[{"id":"0a4b48e476faf89256978f6ec14af548","title":"AI 安全实践 | 应用大语言模型阻断Emotet病毒的传播路径 - FreeBuf网络安全行业门户","content":"AI 安全实践 | 应用大语言模型阻断Emotet病毒的传播路径 - FreeBuf网络安全行业门户\n\n\n\n\n\n\n\n\nExcerpt该方法将解决长期困扰邮件安全网关的难题，彻底破解通过加密压缩包传播病毒的路径。\n\nEmotet是一种恶意软件或病毒，最初于2014年首次被发现。它被认为是最具破坏性和持久性的恶意软件之一，经常用于进行大规模的网络攻击和数据窃取行为。Emotet病毒主要通过电子邮件传播，并采取了一些方法来欺骗用户和绕过安全防护机制。\n在Emotet邮件的传播过程中，病毒会使用加密的压缩包作为附件。这些文档通常是常见的压缩格式，如ZIP或RAR格式。当用户尝试解压它们时，它们会提示用户输入一个密码来解压，同时在邮件正文中提供了相应的密码。这种做法是为了绕过安全网关（邮件网关，或是UTM）对邮件附件的扫描和检测。\n\nLLM带来了新的解决方案对于加密的压缩包，安全网关通常有下面几种应对方法：\n\n  在邮件正文添加警告信息。提示用户注意鉴别压缩包中的文件。\n  使用预置的密码库尝试对压缩包进行穷举解压。\n  使用预定义的正则表达式，尝试从邮件正文中抽取解压密码。\n\n显然，上述的方法都无法从根本上解决这个问题。例如，预定义的正则表达式只能覆盖有限的表达方式。不过，随着LLM的到来，我们找到了新方法。\n从邮件正文中抽取解压密码可以被看作是一种命名实体识别（Named Entity Recognition, NER）任务，其目标是识别出文本中表示密码的实体。\nNER任务通常涉及将文本中的命名实体标记为预定义的类别，如人名、地名、组织机构等。在我们的应用场景中，我们需要识别出表示密码的实体，并将其标记为密码类别。\n应用LLM，传统NLP（自然语言处理）领域的NER任务的执行效果有了很大提升。所以，我们可以借助LLM执行NER任务，帮助我们解决抽取密码的问题。\n训练数据的准备和标注选择合适的NLP开发库对于解决我们的问题很重要。在这里，我们选择了 Spacy 开发库。spaCy是一个流行的Python自然语言处理（NLP）库，被广泛用于文本处理和信息提取任务。它提供了一系列高效的工具和算法，可以帮助开发者处理和分析文本数据。\n另外，我们也需要选择一个基座模型。这里我们选择的是Spacy 提供的en_core_web_trf：\n\nsource: https://spacy.io/models/en#en_core_web_trf\n按照 Spacy 的要求，我们需要准备训练数据，并进行标注。部分原始数据如下图：\n\n使用 Spacy 标注工具标注后的数据如下图：\n\n训练数据并不需要很多，因为我们是基于一个训练好的基座模型进行微调，所以，并不需要大量的数据从头训起，200条即可。这也是微调技术的重要的优点。\n训练的过程训练数据准备完成后，根据下图所示，在Spacy网站上，在线生成训练所需的配置文件 base_config.cfg，并下载下来：\n\nSource: https://spacy.io/usage/training#basics\n创建train.spacy， dev.spacy 和 output 目录，将 Spacy 标注工具生成的二进制训练数据放到 train.spacy 目录中，数据文件的扩展名是 .spcay ，训练程序会自动找这个扩展名的文件。\n目录结构最终如下图所示：\n\n目录train.spacy中放置的 train.spacy 文件就是训练数据。\n目录dev.spacy可放置用于验证的数据，也可以不放置任何验证数据。\n执行下面的命令生成config.cfg\npython -m spacy init fill-config base_config.cfg config.cfg 生成 config.cfg\n执行下面的命令开始训练\npython -m spacy train config.cfg –output ./output –paths.train ./train.spacy –paths.dev ./dev.spacy –gpu-id 0\n在 1660 super 的显卡上，训练花费约数十分钟，小于一个小时。 训练生成的模型存放在 output 目录下，大小约500MB。\n识别效果下面的代码展示了如何加载训练好的数据，对输入的文本执行密码抽取任务：\n\n程序首先加载了模型，然后打印提示符，等待用户输入。我们从网络上收集了一些病毒邮件样本，测试模型的识别效果，并打印出识别所消耗的时间：\n\n除第一次识别会花费较多时间外（推测是加载过程的影响），识别仅需要花费80ms左右。\n结论基于LLM（Large Language Model），利用NLP领域的NER技术，从邮件正文中抽取解压密码是一种完美的解决方案。LLM具有强大的语言理解和上下文理解能力。它可以理解复杂的句子结构和语义关系，有助于识别密码实体以及与其相关的上下文信息。借助微调技术，只需要少量训练数据，就可以在短时间得到满足需要的模型。即使未来出现了某种可以绕过LLM的表达方式，我们也可以快速训练出新的模型，并部署。\n基于本文的方案，不仅是 Emotet 病毒，所有利用加密压缩包的邮件传播方法都被有效的破解了。\n","slug":"freebuf/未命名","date":"2023-09-26T03:59:00.310Z","categories_index":"文章","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"联想拯救者24.5寸显示器 280hz刷新率。\n","slug":"zhihu/未命名","date":"2023-03-01T08:55:11.924Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":" HDMI HDMI（High-Definition Multimedia Interface）是一种高清多媒体接口，它是一种用于传输数字视频和音频的接口。它允许用户将他们的电视机、投影仪、DVD 播放器或其他多媒体设备连接到其他数字设备，如电脑、游戏机或者数字录音机。HDMI 使用 19 条小型连接器来传送信号，这样可以使它在体积上占有小的空间。\n显示器DP输出 无法正常使用的解决方法\n\n首先，检查一下显示器的电源线是否正确插入，以及电源是否已打开。\n\n检查显卡的DP输出端口是否已正确连接到显示器上，并重新连接一下。\n\n在显卡驱动软件中，将DP输出端口设置为主要显示端口。\n\n更新显卡驱动，并尝试重新安装一遍。 \n\n若以上方法均无效，则可能是显示器本身出了问题，应当前往当地售后服务中心，了解进一步信息。\n\n\n显示器DP是什么？ 显示器DP（DisplayPort）是一种通用的高性能数字显示接口，由英特尔公司推出。它可以提供高达8.64Gbps的带宽，并且可以支持分辨率最高达4K@60Hz的图像传输。\nVGA  :Video Graphics ArrayVGA 是视频图形阵列的缩写，是一种用于显示图像的标准，可以将图像传输到显示器上。它使用15针或更多的连接器来传输信号，通常使用RGB彩色信号。VGA标准于1987年推出，主要用于PC机上的显示器。它有640×480分辨率的标准版本，但也有800×600、1024×768、1280×1024、1600×1200和2048×1536等不同版本。\nDVI 中文解释DVI是Digital Video Interface（数字视频接口）的缩写，是一种用于传输数字视频信号的接口。它使用一组有序的数字信号来传输图像、声音和其他信息。DVI 接口主要用于连接显示器和个人电脑之间，以便在显示器上显示个人电脑的图形或文本。\nDVI (Digital Video Interface) output is a type of digital signal used primarily for connecting video sources, such as computers and monitors, to displays. It is the most common type of interface used in computer graphics, and is found in many modern graphics cards and monitors. DVI output is capable of transmitting both digital and analog signals, allowing for higher resolutions and better image quality than analog connections. Additionally, it supports HDCP (High-bandwidth Digital Content Protection) encryption, which helps prevent unauthorized copying of digital content. Compared to other digital video interfaces such as HDMI and DisplayPort, DVI is an older technology and does not support newer features such as HDCP 2.2, HDR (High Dynamic Range), or higher resolutions. Additionally, DVI connectors are larger than their HDMI and DisplayPort counterparts, making them difficult to use in cramped spaces.\nDespite its shortcomings, DVI is still a popular choice for connecting video sources to displays due to its widespread availability and compatibility with most graphics cards and monitors. For users who need the latest features and highest resolutions, however, it may be worth investing in a newer interface such as HDMI or DisplayPort.\n","slug":"zhihu/显示器各种接口","date":"2023-02-27T05:17:52.583Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"在搭载 M1 及 M2 芯片 MacBook 设备上玩 Stable Diffusion 模型\n\n\n\n\n\n\n\n\nExcerpt\n\n本篇文章，我们聊了如何使用搭载了 Apple Silicon 芯片（M1 和 M2 CPU）的 MacBook 设备上运行 Stable Diffusion 模型。 \n写在前面 \n在上一篇文章《使用 Docker 来快速上手中文 Stable Diffusion 模型：太乙》中，我们聊过…\n\n本篇文章，我们聊了如何使用搭载了 Apple Silicon 芯片（M1 和 M2 CPU）的 MacBook 设备上运行 Stable Diffusion 模型。\n写在前面在上一篇文章《使用 Docker 来快速上手中文 Stable Diffusion 模型：太乙》中，我们聊过了如何使用配备了“传统的 Nvidia 显卡”的设备（云服务器）来运行 Stable Dif fusion 模型。在之前的文章中我提到过，接下来将聊聊如何使用 CPU 来运行 “SD 模型应用”。\n本篇文章，我们就先从 Apple Silicon 这类 ARM 芯片开始（M1 / M1 Pro / M1 Max / M1 Ultra / M2），用 CPU 来运行 Stable Diffusion 。十一月末，为 Apple Core ML Tools 开源项目贡献代码的主要工程师之一，正式发布了一个新的开源项目：apple/ml-stable-diffusion。\n下面我们就来聊聊这个项目该如何简单、快速的上手。\n支持运行的设备本文中，我的实验环境是 Apple M2 CPU 的 MacBook Pro，机器内存容量为 16GB。同样还能够运行本文的设备包含：\n\n  2022 年生产的MacBook Air (M2)、13寸的 MacBook Pro (M2)、Mac Studio (2022)\n\n  2021 年生产的 14寸和16寸的 MacBook Pro、24寸的 iMac (M1)\n\n  2020 年生产的 Mac mini (M1)、MacBook Air (M1)、13寸的 MacBook Pro (M1)\n\n  当然，还有搭载了 M1 芯片的第五代 iPad Pro\n\n\n基础环境准备想要在 ARM 芯片的 Mac 设备上运行这个模型应用，我们需要做几件事：\n\n  准备 Python 基础运行环境\n\n  准备软件运行所需要的软件包\n\n\n为 MacOS 设备安装 Python 环境管理工具在《用让新海诚本人惊讶的 AI 模型制作属于你的动漫视频》这篇文章中，我分享过关于“使用 Conda 简化 Python 程序环境准备工作”，正巧年底 Conda 版本更新，这里就顺带也更新一个版本的安装和使用方式。\n\n虽然我们可以从 Conda 官方网站的下载页面得到合适的安装程序。不过，我一般从 Conda 官方的 “Archive” 页面进行下载，因为能够更加直观的看到，我们想要下载的目标文件的各种信息，比如：名称、版本、尺寸、更新时间、文件指纹。\n12345Filename                          Size   Last Modified       SHA256Anaconda3-2022.10-MacOSX-arm64.sh 472.5M 2022-10-17 16:15:38 200700077db8eed762fbc996b830c3f8cc5a2bb7d6b20bb367147eb35f2dcc72\n\n这里为了更快的得到下载文件，可以通过“清华源”中的 Conda 镜像来加速下载过程。比如，官方的原始下载地址 https://repo.anaconda.com/archive/Anaconda3-2022.10-MacOSX-arm64.sh ，那么加速下载的地址就是：https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2022.10-MacOSX-arm64.sh，完成 Conda 安装文件下载之后，我们可以执行 shasum -a 256 来验证下载文件的完整性：\n12345shasum -a 256 ~/Downloads/Anaconda3-2022.10-MacOSX-arm64.sh 200700077db8eed762fbc996b830c3f8cc5a2bb7d6b20bb367147eb35f2dcc72  /Users/soulteary/Downloads/Anaconda3-2022.10-MacOSX-arm64.sh\n\n接着，执行 bash Anaconda3-2022.10-MacOSX-arm64.sh 进行安装，“一路 Next”，完成程序的安装即可。\n和之前的文章里的观点相同，国内用户推荐在使用 Conda 时，先进行软件源配置操作。这样可以减少在下载软件包过程中造成的不必要时间浪费。使用 vi ~/.condarc 编辑 Conda 配置文件，在其中加入下面的内容（以“清华源”为例）：\n12345channels:- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/- https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/- defaultsshow_channel_urls: true\n\n在完成了 ~/.condarc 的内容修改后，重启 Shell。然后，使用 conda info 查看配置是否生效：\n123conda infoactive environment : baseactive env location : /Users/soulteary/anaconda3shell level : 1user config file : /Users/soulteary/.condarcpopulated config files : /Users/soulteary/.condarcconda version : 22.9.0conda-build version : 3.22.0python version : 3.9.13.final.0virtual packages : __osx=13.0.1=0__unix=0=0__archspec=1=arm64base environment : /Users/soulteary/anaconda3  (writable)conda av data dir : /Users/soulteary/anaconda3/etc/condaconda av metadata url : Nonechannel URLs : https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/osx-arm64https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/noarchhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/osx-arm64https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/noarchhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/osx-arm64https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/noarchhttps://repo.anaconda.com/pkgs/main/osx-arm64https://repo.anaconda.com/pkgs/main/noarchhttps://repo.anaconda.com/pkgs/r/osx-arm64https://repo.anaconda.com/pkgs/r/noarchpackage cache : /Users/soulteary/anaconda3/pkgs/Users/soulteary/.conda/pkgsenvs directories : /Users/soulteary/anaconda3/envs/Users/soulteary/.conda/envsplatform : osx-arm64user-agent : conda/22.9.0 requests/2.28.1 CPython/3.9.13 Darwin/22.1.0 OSX/13.0.1UID:GID : 502:20netrc file : Noneoffline mode : False\n\n如果输出的内容中包含我们刚刚设置的“清华源”，就说明我们的配置生效了。\n快速准备 MacOS 上的 Python 运行环境在完成 Conda 的安装之后，我们就可以用它来快速的创建不影响本地机器环境（MacOS），只和项目关联的干净的 Python 运行环境了。\n检查 apple/ml-stable-diffusion/setup.py 文件，我们可以看到，项目支持运行的环境有 Python 3.7 ～ Python 3.9，那我们随便取个中间数 3.8 吧：\n123conda create -n coreml_stable_diffusion python=3.8 -y\n\n等待上面的命令执行完毕，我们指定的名为 coreml_stable_diffusion 的环境就初始化好啦，环境使用的具体 Python 版本为 3.8 （虚拟环境的版本可以和系统不一样）。\n当然，默认创建好之后，并不会直接切换到创建好的新环境，我们还需要使用命令，来完成环境的切换。\n123conda activate coreml_stable_diffusion\n\n当命令执行完毕之后，我们会看到终端前的展示字符串会出现变化，展示我们当前正所处于的虚拟环境：\n12345(base) # conda activate coreml_stable_diffusion(coreml_stable_diffusion) #\n\n因为，我们后续需要使用 pip 命令来安装程序依赖的软件包，为了减少时间的浪费，这里我们同样可以使用命令，来调整软件下载源为“清华源”：\n123pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n如果我们关闭了终端，你会发现环境“失效了”，这时还是可以用和上文中提到的相同的命令 conda activate，来激活（切换）回我们之前配置好的环境。\n123conda activate coreml_stable_diffusion\n\n避免 MacOS 上 Tokenizers 软件包安装出错如果你经常在 MacOS 上折腾 “Huggingface” 等项目，尤其是运行相对新一些的模型项目，大概率会遇到 “Failed building wheel for tokenizers”这个问题。\n解决问题的方法很简单，只需要在 MacOS 上完成 Rust 的安装即可：\n123curl https://sh.rustup.rs -sSf | sh\n\n完成安装之后，可以使用 rustc --version 来做一个简单的命令“可执行”的验证：\n12345# rustc --versionrustc 1.65.0 (897e37553 2022-11-02)\n\n当然，为了加速 rust 软件包的下载，同样建议在 Rust 的配置文件（~/.cargo/config）中，完成“清华源”的配置：\n12345678910111213# vi ~/.cargo/config[source.crates-io]registry = &quot;https://github.com/rust-lang/crates.io-index&quot;replace-with = &#x27;tuna&#x27;[source.tuna]registry = &quot;https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git&quot;\n\n完成配置文件的保存，接下来在遇到需要 Rust 编译，或下载依赖包的时候，速度也会变的飞快。\n如果你没有补全 rustc 的依赖，那么大概率会遇到类似下面的报错：\n123456789Building wheels for collected packages: pyyaml, tokenizersBuilding wheel for pyyaml (pyproject.toml) ... doneCreated wheel for pyyaml: filename=PyYAML-6.0-cp38-cp38-macosx_11_0_arm64.whl size=45335 sha256=e27236fa2771f8d6ffbba947c48931a8fcf95ad33d77b91d4c693d04d5344710Stored in directory: /Users/soulteary/Library/Caches/pip/wheels/fe/be/21/a238a4532fd03d32998d6a07c6b4f572ea8cb4eaa89ddc2a41Building wheel for tokenizers (pyproject.toml) ... errorerror: subprocess-exited-with-error× Building wheel for tokenizers (pyproject.toml) did not run successfully.│ exit code: 1╰─&gt; [51 lines of output]running bdist_wheelrunning buildrunning build_pycreating buildcreating build/lib.macosx-11.1-arm64-cpython-38creating build/lib.macosx-11.1-arm64-cpython-38/tokenizerscopying py_src/tokenizers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/modelscopying py_src/tokenizers/models/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/modelscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/decoderscopying py_src/tokenizers/decoders/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/decoderscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/normalizerscopying py_src/tokenizers/normalizers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/normalizerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/pre_tokenizerscopying py_src/tokenizers/pre_tokenizers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/pre_tokenizerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/processorscopying py_src/tokenizers/processors/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/processorscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/trainerscopying py_src/tokenizers/trainers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/trainerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/byte_level_bpe.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/sentencepiece_unigram.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/sentencepiece_bpe.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/base_tokenizer.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/char_level_bpe.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/bert_wordpiece.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolscopying py_src/tokenizers/tools/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolscopying py_src/tokenizers/tools/visualizer.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolscopying py_src/tokenizers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizerscopying py_src/tokenizers/models/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/modelscopying py_src/tokenizers/decoders/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/decoderscopying py_src/tokenizers/normalizers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/normalizerscopying py_src/tokenizers/pre_tokenizers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/pre_tokenizerscopying py_src/tokenizers/processors/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/processorscopying py_src/tokenizers/trainers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/trainerscopying py_src/tokenizers/tools/visualizer-styles.css -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolsrunning build_extrunning build_rusterror: can&#x27;t find Rust compilerIf you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.To update pip, run:pip install --upgrade pipand then retry package installation.If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.[end of output]note: This error originates from a subprocess, and is likely not a problem with pip.ERROR: Failed building wheel for tokenizersSuccessfully built pyyamlFailed to build tokenizersERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n\n完成 Stable Diffusion 项目的初始化我们可以通过 git clone 命令，或者直接下载包含代码的压缩包，来获得项目的代码：\n123git clone https://github.com/apple/ml-stable-diffusion.git\n\n项目比较小，所以下载速度还是蛮快的：\n123456789101112131415# git clone https://github.com/apple/ml-stable-diffusion.gitCloning into &#x27;ml-stable-diffusion&#x27;...remote: Enumerating objects: 65, done.remote: Counting objects: 100% (14/14), done.remote: Compressing objects: 100% (13/13), done.remote: Total 65 (delta 0), reused 14 (delta 0), pack-reused 51Receiving objects: 100% (65/65), 9.05 MiB | 406.00 KiB/s, done.Resolving deltas: 100% (1/1), done.\n\n将工作目录切换到项目目录中，然后使用 pip install 完成项目依赖的安装：\n12345cd ml-stable-diffusionpip install -r requirements.txt\n\n至此，基础环境准备工作就都就绪了。\n转换和运行模型应用基础环境就绪之后，我们需要转换 Huggingface 上的 PyTorch / TF 开放模型到 Apple Core ML 模型格式。\n转换 PyTorch 模型为 Apple Core ML 模型项目仓库中 python_coreml_stable_diffusion/torch2coreml.py 文件中，封装了调用 coremltools.models.MLModel 工具方法来转换其他格式模型到 Core ML 模型的逻辑：\n1234567coreml_model = coremltools.models.MLModel(...)coreml_model.convert(...)coreml_model.save(...)\n\n所以，作为用户我们的使用就比较简单了，只需要执行下面的命令：\n123python -m python_coreml_stable_diffusion.torch2coreml --convert-unet --convert-text-encoder --convert-vae-decoder --convert-safety-checker -o ./models\n\n命令执行会比较久，十来分钟左右，包含从 Huggingface 下载模型，加载并转换模型格式。默认情况下，模型使用的是 CompVis/stable-diffusion-v1-4，如果你希望使用其他的模型，可以通过添加 --model-version 参数，支持的模型版本除了默认的 “v1.4” 之外，还有： runwayml/stable-diffusion-v1-5 和 stabilityai/stable-diffusion-2-base。\n如果你使用的 Mac 设备是 8GB 版本，在执行过程中，会得到内存不足之类的提示，可以用下面的命令进行替换：\n123456789python -m python_coreml_stable_diffusion.torch2coreml --convert-vae-decoder -o ./models &amp;&amp; \\python -m python_coreml_stable_diffusion.torch2coreml --convert-unet -o ./models &amp;&amp; \\python -m python_coreml_stable_diffusion.torch2coreml --convert-text-encoder -o ./models &amp;&amp; \\python -m python_coreml_stable_diffusion.torch2coreml --convert-safety-checker -o ./models &amp;&amp;\n\n命令执行完毕，我们将在 ./models 目录，得到必须的四个模型，尺寸都不算小：\n123456789# du -hs ./models/*580M./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage235M./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage1.6G./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage95M./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage\n\n当然，相比 HuggingFace 的原始模型来说，还是小了一些的：\n12345du -hs ~/.cache/huggingface/diffusers/models--CompVis--stable-diffusion-v1-4/ 5.1G/Users/soulteary/.cache/huggingface/diffusers/models--CompVis--stable-diffusion-v1-4/\n\n运行转换后的模型进行验证完成模型构建之后，我们可以运行模型，来验证模型转换是否成功：\n123python -m python_coreml_stable_diffusion.pipeline --prompt &quot;magic book on the table&quot; -i ./models -o ./output --compute-unit ALL --seed 93\n\n在上面的命令中，我们做了几件事，告诉程序使用 ./models 目录中的模型进行计算，将生成的图谱保存在 ./output 目录中，允许使用所有类型的运算单元（CPU/GPU），使用一个固定的随机数种子，确保每次生成的结果都是一样的，方便我们进行测试复现。当然，最重要的是，我们将要生成图片的文本描述写在 --prompt 参数中，告诉模型应用要生成“一本放在桌子上的魔法书”。如果你的设备只有 8GB 的内存，这里需要调整下 --compute-unit 参数，指定参数值为 CPU_AND_NE。\n程序运行之后，需要等几分钟：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253WARNING:coremltools:Torch version 1.13.0 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.INFO:__main__:Setting random seed to 93INFO:__main__:Initializing PyTorch pipe for reference configurationFetching 16 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00&lt;00:00, 9876.21it/s]INFO:__main__:Removed PyTorch pipe to reduce peak memory consumptionINFO:__main__:Loading Core ML models in memory from ./modelsINFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.4 seconds.INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 73.1 seconds.INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 5.5 seconds.INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 2.2 seconds.INFO:__main__:Done.INFO:__main__:Initializing Core ML pipe for image generationINFO:__main__:Stable Diffusion configured to generate 512x512 imagesINFO:__main__:Done.INFO:__main__:Beginning image generation.100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [01:50&lt;00:00,  2.17s/it]INFO:__main__:Generated image has nsfw concept=False\n\n当程序运行完毕之后，我们将能够在 ./output 目录中，找到生成的图片。\n\n但是，每次使用都要等三四分钟才能得到图片，未免太慢了。而且想生成不同的图，不论是需要调整“随机数种子”，还是要改变“描述文本”，都得在命令行中完成，遇到文本特别长的时候，非常不方便。\n有没有什么方法，可以让 ML Stable Diffusion 的生成图片，使用起来方便些呢？\n为 ML Stable Diffusion 编写一个 Web UI在以往和 Python 相关的内容里，我提到过 gradio 这个有趣的工具，能够为 Python 应用，快速创建简洁美观的 Web 界面。Huggingface 中非常多的应用界面都是用它完成的。\n\n为了解决上面的问题，我们可以用它来创建一个 Web 界面，把 ML Stable Diffusion 的图片生成和 Web 界面“绑定”到一起。实现代码很简单，不到 100 行：\n12345import python_coreml_stable_diffusion.pipeline as pipelineimport gradio as grfrom diffusers import StableDiffusionPipelinedef init(args):pipeline.logger.info(&quot;Initializing PyTorch pipe for reference configuration&quot;)pytorch_pipe = StableDiffusionPipeline.from_pretrained(args.model_version,use_auth_token=True)user_specified_scheduler = Noneif args.scheduler is not None:user_specified_scheduler = pipeline.SCHEDULER_MAP[args.scheduler].from_config(pytorch_pipe.scheduler.config)coreml_pipe = pipeline.get_coreml_pipe(pytorch_pipe=pytorch_pipe,mlpackages_dir=args.i,model_version=args.model_version,compute_unit=args.compute_unit,scheduler_override=user_specified_scheduler)def infer(prompt, steps):pipeline.logger.info(&quot;Beginning image generation.&quot;)image = coreml_pipe(prompt=prompt,height=coreml_pipe.height,width=coreml_pipe.width,num_inference_steps=steps,)images = []images.append(image[&quot;images&quot;][0])return imagesdemo = gr.Blocks()with demo:gr.Markdown(&quot;&lt;center&gt;&lt;h1&gt;Core ML Stable Diffusion&lt;/h1&gt;Run Stable Diffusion on Apple Silicon with Core ML&lt;/center&gt;&quot;)with gr.Group():with gr.Box():with gr.Row():with gr.Column():with gr.Row():text = gr.Textbox(label=&quot;Prompt&quot;,lines=11,placeholder=&quot;Enter your prompt&quot;,)with gr.Row():btn = gr.Button(&quot;Generate image&quot;)with gr.Row():steps = gr.Slider(label=&quot;Steps&quot;, minimum=1,maximum=50, value=10, step=1)with gr.Column():gallery = gr.Gallery(label=&quot;Generated image&quot;, elem_id=&quot;gallery&quot;)text.submit(infer, inputs=[text, steps], outputs=gallery)btn.click(infer, inputs=[text, steps], outputs=gallery)demo.launch(debug=True, server_name=&quot;0.0.0.0&quot;)if __name__ == &quot;__main__&quot;:parser = pipeline.argparse.ArgumentParser()parser.add_argument(&quot;-i&quot;,required=True,help=(&quot;Path to input directory with the .mlpackage files generated by &quot;&quot;python_coreml_stable_diffusion.torch2coreml&quot;))parser.add_argument(&quot;--model-version&quot;,default=&quot;CompVis/stable-diffusion-v1-4&quot;,help=(&quot;The pre-trained model checkpoint and configuration to restore. &quot;&quot;For available versions: https://huggingface.co/models?search=stable-diffusion&quot;))parser.add_argument(&quot;--compute-unit&quot;,choices=pipeline.get_available_compute_units(),default=&quot;ALL&quot;,help=(&quot;The compute units to be used when executing Core ML models. &quot;f&quot;Options: &#123;pipeline.get_available_compute_units()&#125;&quot;))parser.add_argument(&quot;--scheduler&quot;,choices=tuple(pipeline.SCHEDULER_MAP.keys()),default=None,help=(&quot;The scheduler to use for running the reverse diffusion process. &quot;&quot;If not specified, the default scheduler from the diffusers pipeline is utilized&quot;))args = parser.parse_args()init(args)\n\n我们将上面的代码保存为 web.py，同样放在项目的 python_coreml_stable_diffusion 目录中。然后执行命令：\n123python -m python_coreml_stable_diffusion.web -i ./models --compute-unit ALL\n\n命令执行后，我们将得到类似下面的日志：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647WARNING:coremltools:Torch version 1.13.0 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.INFO:python_coreml_stable_diffusion.pipeline:Initializing PyTorch pipe for reference configurationFetching 16 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00&lt;00:00, 16396.01it/s]INFO:python_coreml_stable_diffusion.pipeline:Removed PyTorch pipe to reduce peak memory consumptionINFO:python_coreml_stable_diffusion.pipeline:Loading Core ML models in memory from ./modelsINFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.4 seconds.INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 73.5 seconds.INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 6.0 seconds.INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackageINFO:python_coreml_stable_diffusion.coreml_model:Done. Took 1.9 seconds.INFO:python_coreml_stable_diffusion.pipeline:Done.INFO:python_coreml_stable_diffusion.pipeline:Initializing Core ML pipe for image generationINFO:python_coreml_stable_diffusion.pipeline:Stable Diffusion configured to generate 512x512 imagesINFO:python_coreml_stable_diffusion.pipeline:Done.Running on local URL:  http://0.0.0.0:7860To create a public link, set `share=True` in `launch()`.\n\n前半段日志是不是很熟悉，和我们运行模型进行验证时，基本一致。但是在日志的结束处，我们看到程序启动了 Web 服务，并监听了 7860 端口。打开浏览器，访问这个地址，我们就能看到预期中的 Web UI 啦。完整的项目代码，可以参考 GitHub 的提交。\n\n都能看到界面了，不试一试是不是说不过去，我这里简单输入“colorful startrails” （绚丽星轨），然后点击 “Generate image” ，等待程序进行图片生成，图片生成完毕，将出现在右侧的 “Generated image” 图片展示框内。\n\n是不是还挺方便的，想要生成图片只需要调整文本框中的 “prompt” 文本，然后点击 “Generate image” ，等待结果展示在页面上就行了，不用去调整命令行，也不用去翻找文件夹里的图片了。并且，因为我们将程序当服务运行了起来，被模型加载只需要一次，不再需要像上文一样，每次生成图片都要先加载模型，再进行计算，能节约不少时间。\n其他：一个低级 Bug使用过其他版本的图片生成模型的同学，手里一定有“大段咒语”，当我们将超级长的咒语扔到 ML Stable Diffusion 中的时候，大概率会遇到类似下面的报错：\n12345Traceback (most recent call last):File &quot;/Users/soulteary/anaconda3/envs/coreml_stable_diffusion2/lib/python3.8/runpy.py&quot;, line 194, in _run_module_as_mainreturn _run_code(code, main_globals, None,File &quot;/Users/soulteary/anaconda3/envs/coreml_stable_diffusion2/lib/python3.8/runpy.py&quot;, line 87, in _run_codeexec(code, run_globals)File &quot;/Users/soulteary/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py&quot;, line 534, in &lt;module&gt;main(args)File &quot;/Users/soulteary/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py&quot;, line 485, in mainout_path = get_image_path(args)File &quot;/Users/soulteary/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py&quot;, line 444, in get_image_pathos.makedirs(out_folder, exist_ok=True)File &quot;/Users/soulteary/anaconda3/envs/coreml_stable_diffusion2/lib/python3.8/os.py&quot;, line 223, in makedirsmkdir(name, mode)OSError: [Errno 63] File name too long: &#x27;./output/.........&#x27;\n\n想要避免这个问题，只有两个方法：\n1.  缩短你的 Prompt 文本长度\n2.  修改代码，避免出现超级长的文本\n关于如何用代码解决这个问题，我在 GitHub 的这个 PR 中有提到，感兴趣的同学可以自行“复制粘贴”，来修正这个问题。或者，等等看官方是否会合并这个请求，更新程序版本即可解决问题 😄\n最后这篇文章就先写到这里啦。关于 Apple Mac 生态和模型的话题，其实还有不少可以聊的东西，希望后面有机会能够慢慢展开。\n–EOF\n\n我们有一个小小的折腾群，里面聚集了一些喜欢折腾的小伙伴。\n在不发广告的情况下，我们在里面会一起聊聊软硬件、HomeLab、编程上的一些问题，也会在群里不定期的分享一些技术沙龙的资料。\n喜欢折腾的小伙伴，欢迎阅读下面的内容，扫码添加好友。\n\n  关于“交友”的一些建议和看法\n\n  添加好友，请备注实名和公司或学校、注明来源和目的，否则不会通过审核。\n\n  关于折腾群入群的那些事\n\n\n","slug":"web/stabledissfusion","date":"2023-02-16T07:45:35.482Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":" C语言求字符变量的后8位字符串的C语言实现。 可以使用位运算来实现：\nunsigned char x;\nunsigned char last8_str[9]; //存储最后8位字符串 \nfor (int i = 0; i &lt; 8; i++) {    last8_str[i] = (x &amp; (1 &lt;&lt; (7 - i))) ? ‘1’ : ‘0’; //按位取出x的最后8位} \nlast8_str[8] = ‘\\0’; //字符串结束\nC语言取字符串后8位 可以使用 strlen() 函数获取字符串的长度，然后运行以下代码：\n// 获取字符串长度int len = strlen(str);// 获取后8位字符char *result = &amp;str[len-8];\n为什么Jekyll不监听文件变化，进行实时静态文件生成？Jekyll的基本功能是为用户提供一个静态文件生成系统，而不是一个实时文件监控和变化检测系统。Jekyll的实时文件监控和变化检测功能，需要用户手动启动（通过命令行），才能生效。\nJekyll实时文件监听的命令行指令是什么？ 答案：jekyll serve –watch\n达美乐、必胜客、凯撒那个比萨最好吃，那么有什么区别？\n达美乐提供的披萨是以传统的意大利风味为特色，他们的披萨面团最为薄，做出来的口感最为脆而不太甜；必胜客披萨则是以美式风味为特征，面团厚度适中，口感十分香甜；凯撒披萨则是以浓郁的海鲜口味为特点，比其它品牌更加重口感。总之，三者在口味上都有其各自独特的风格和特点。\n","slug":"other/临时问题","date":"2023-02-13T06:00:08.863Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"潜入式开发的就业前景好，还是互联网后端开发好？\n潜入式开发的就业前景取决于你的个人能力和市场定位，但一般来说，互联网后端开发的就业前景要优于潜入式开发。\nchill out mix是什么？Chill out mix是一种流行的音乐风格，旨在将不同风格的音乐融合在一起，制作出来的音乐通常有节奏感，并有一种放松、休闲、压力释放的效果。\n","slug":"zhihu/潜入式开发的就业前景好，还是互联网后端开发好？","date":"2023-02-13T05:33:18.833Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"17c7f8a2a28343c5bbea587ebdcd485c","title":"GPT2与GPT3的区别是什么？","content":"GPT2与GPT3的区别是什么？ GPT2和GPT3之间的主要区别是模型的大小。GPT2模型的参数大约为1.5亿，而GPT3模型的参数大约为175亿。此外，GPT2是通过预先训练一个语言模型来实现的，而GPT3是一个通过机器学习不断训练的深度神经网络。因此，GPT3可以在新的任务上被更快地训练，并可以使用更少的数据来实现。\n","slug":"zhihu/GPT2与GPT3的区别是什么？","date":"2023-02-13T05:26:46.266Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"PC的iCloud的位置。cd /Library/Mobile\\ Documents/comapple~CloudDocs\n手机上Obsidian文件夹的位置。cd /Library/Mobile\\ Documents/iCloud\\md~obsidiancd /Library/Mobile\\ Documents/iCloudmd~obsidian/Documents\n","slug":"other/icloud的文件夹的位置","date":"2023-02-13T05:13:56.235Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"e564ce5c4856dfbed477325743829e87","title":"iCloud的文件夹的位置","content":"iCloud的文件夹的位置PC的iCloud的位置。cd /Library/Mobile\\ Documents/comapple~CloudDocs\n手机上Obsidian文件夹的位置。cd /Library/Mobile\\ Documents/iCloud\\md~obsidiancd /Library/Mobile\\ Documents/iCloudmd~obsidian/Documents\n","slug":"other/iCloud的文件夹的位置","date":"2023-02-13T05:13:56.235Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"","slug":"2023-02-13","date":"2023-02-13T05:11:38.429Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f3a7a1ae5810a1d115aa263fefb11fd2","title":"<% tp.file.title %>","content":"&lt;% tp.file.title %&gt;","slug":"templater/安书模板","date":"2023-02-13T04:58:27.063Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"05ce0dc6ba8a405a578fd59c1315c42c","title":"MDA高度键帽是谁发明的？","content":"&lt;&lt; [[2023-02-12]] | [[2023-02-14]] &gt;&gt;\nMDA高度键帽是谁发明的？机械键盘MDA高度键帽是谁发明的？MDA高度键帽是由IBM的研究员史蒂夫·克拉克（Steve Cark）在1981年发明的。\n","slug":"keyboard/MDA高度键帽是谁发明的？","date":"2023-02-13T04:20:31.961Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"8beb6aaa8dc474d4c19edc94443dc527","title":"请问静电容键盘 和 静音红轴键盘，哪款更适合长期大量的打字？希望从主要从静音效果、打字手感两点来说。？","content":"什么样的机械键盘适合长时间打字 ？ 最适合长时间打字的机械键盘是Niz静电容键盘。Niz电容键盘采用了一种新型的传感技术，它可以检测到手指的轻度触碰，而不必实实地敲击键盘上的按键。这种技术可以使用户打字时更加轻松舒适，也能大大减少关节和筋膜的压力，使用者得以保护到他们的手部健康。另外，Niz电容键盘也有很好的耐久性，可以经受多年的使用考验。\n\n\n\n\n\n\n\n\n\nExcerpt这么说吧，同样是35克，按压力的轴体， 经电容的反弹和回馈，更适合和长时间打字。当然，你也可以用Poron…\n\n这么说吧，同样是35克，按压力的轴体， 经电容的反弹和回馈，更适合和长时间打字。\n静电容轴体与机械键盘静音轴那个更适合文字输入208 播放 · 1 赞同视频![点击可播放视频](\n当然，你也可以用Poron的定位板，夹心棉和Gasget结构来形成类似的效果，或者像没有钢板为了省钱的g80-3494红轴。 而经电容，不用这么折腾也可以达到这种软糯无力的效果，配合丝滑的POM键帽就更适合了，软糯丝滑，这手感就类似什么呢？\n\n目前中国市场最受欢迎的计算机安全书籍是《黑客与画家》（Hackers and Painters），由美国顶尖黑客兼作家Paul Graham所著。这本书深入浅出地介绍了黑客文化及其在计算机世界中的重要性，并探讨了一些基本的计算机原理和技巧。此外，该书还介绍了很多“真正”的黑客都做了什么。\n静音轴\n\n静音轴\n\n静音轴\n如果喜欢线性轴、轻按压力、 静音轴，性价比高的一元以下的静音轴，可以选40克的高特水蜜桃静音轴，比红轴45克要轻，比静电容35克要重一些，但基本很轻了不顶手，手感很好。 我用蔷薇红35克，还有31克青绿轴，35克Niz静电容轴平滑过度到这个静音轴。\n\n\n本人码农，长时间打字，红轴键盘有N把、静电容键盘两吧。\n1.静音红轴与红轴差别\n静音红轴的按压力克数，要比红轴的大， 如果正常cherry的红轴是45g，静音版基本在50g。\n1.1 先说结论\n从长时间打字的来看， 35g按压力克数的静电容键盘、35g-37g的线轴轴体机械键盘更适合打字。 为什么？ 因为手感很轻。\n\n2. 红轴与线性轴的关系2.1 红轴与黑轴红轴属于线性轴体里的一种， 常用线性轴除了红轴，还有黑轴，但是黑轴按压力克数大，按时间长累，不适合打长时间按字。\n2.2 红轴与Box红轴基本上很多就是说新版樱桃轴的弹簧声，Box红轴，轴体晃动成度更低。\n2.3 红轴与其他线轴银轴、玫瑰轴（Rose）、巧克力粉种。除了传统的红轴外，还这三种轴， 其实还有很多种，我就是选了这三个比较典型的线轴。\n银轴：键程短，我觉得比红轴还适合打字（不考虑误触摸）。\n玫瑰轴：很轻35g按压力克数，学时间打字不伤手。\n巧克力粉轴：巧克力粉，其实就是轴体的外壳是巧克力，轴的十字键是粉色的，线性轴比红还轻一些有的是40g，反馈力适中，打字也可以。\n\n\n3. 静电容键盘最常见的就是燃风、 HHKB、NIZ。\n3.1 HHKB对程序员比较友好，特别是针对emac、vim这种编辑器，但所有的这种小键盘都有一个问题，按组合键盘麻烦，但是省地方。\n\n为什么有人说HHKB和IKBC红轴差不多呢，其中的一个原因，主要是他们都是线性轴，按压力克数都是40g以上，不会像45g机械和35g静电容手感差那么多，其实我也用过一段45g的niz静电容，其实和红轴的确接近，便还是不一样，一个是轴体的稳定晃动程度，一个是回弹的力度。\n3.2 燃风高端键盘，轴体稳定性更好，做工也好，就是贵。打字不累， 还静音的， 谁也比不过这货。\n\n3.3 NIZ香吗国产静电容键盘，总体价格相对其他品牌比较亲民， 有线版本600多元钱。我平时打字，单位一把ATOM 68 PBT键帽白色款， 家里用了一款有线（不用移动考虑便携）POM键帽（比较丝滑）黑色款。\n\n为什么我说这种键盘更适合打字？\n\n\n实践出真知，我用了多少把键盘，最后感觉打字不累的，还是是3种轴体：35g静电容、35-37g机械线性轴，银轴。\n我平时一个是敲代码，一个是有时候写点书稿，都是用这些键盘完成的。\n4.0 总结适合打字看三点，这三点做到了， 静电容轴，还是机械轴都省力，都适合打字。\n一看，按键操作力要轻。 二看，操作键程尽量短。 三看， 键帽要符合人体工学。\n如果静音红轴的触发操作力足够轻划没有问题，打起字来不一起比经电容费力。\n静电容推荐NIZ，机械轴推荐37克操作按压力的分粉轴。\n","slug":"keyboard/Niz静电容键盘","date":"2023-02-10T08:54:36.745Z","categories_index":"文章","tags_index":"键盘（计算机）,机械键盘,蓝牙键盘,无线键盘,静电容式键盘","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"为什么听了很多歌后觉得beyond没那么牛逼? 这可能是因为你对新的流行音乐更加熟悉，而Beyond的音乐风格偏古典，所以可能会让你感觉有些落后，或者说没有那么牛逼。但是如果你再仔细听一下，就会发现Beyond的歌曲多么有诗意，也很有层次感。他们的歌词中充满了对生命的思考、对心灵的思考、对宇宙的思考，这是很多当代歌手所无法企及的。Beyond在中国流行音乐界独树一帜，其影响力不容小觑。\n","slug":"zhihu/为什么听了很多歌后觉得beyond没那么牛逼?","date":"2023-02-10T05:39:12.476Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"a4a020c2ea2cca22323ee90d52974113","title":"薄膜键盘与机械键盘的区别是什么？","content":"secbooks.cn\n\n\n\n\n\n\n\n\nExcerpt安全书\n\n薄膜键盘与机械键盘的区别是什么 ？\n\n结构差异：薄膜键盘是由一层薄膜，一层硅胶和一块金属板组成，而机械键盘是由单独的每个按键机械开关与PCB板组成。\n抗干扰性：机械键盘具有较强的抗干扰能力，可以在受到外界干扰时保证正常使用；而薄膜键盘则会因为外界干扰而出现误触发现象。\n声音差异：机械键盘会产生击键的声音；而薄膜键盘是无声的。\n驱动工作原理不同：机械键盘使用机械开关进行信号传递；而薄膜键盘则使用光学传感器进行信号传递。\n\n静电容轴和机械键盘轴的区别主要是该如何反馈信息给用户。静电容轴将通过按下按键来向用户提供反馈，而机械键盘轴将通过弹跳回来来提供反馈。静电容轴也提供更长的使用寿命，因为它们不需要通过物理连接才能反馈信息。而机械键盘轴则会在时间的推移中失去其抗腐蚀性和可灵敏度，从而造成不精确的输入。\n","slug":"chat/薄膜键盘与机械键盘的区别是什么","date":"2023-02-09T07:37:53.863Z","categories_index":"文章","tags_index":"安全书","author_index":"shengnoah"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":" 答：\n\n先去了解当地的房地产市场，了解当前沈阳房价及楼市动态。\n根据自身家庭收入及偿还能力，制定好购房预算，合理选择住房面积、位置、价格等参数。\n多参考朋友的意见，多看相关房产评估信息，咨询相关专业顾问。\n关注本地政府出台的新政策，借助新政对购房有利的条件进行选房。\n通过多方途径寻找合适的物业，如前往开发商展厅、在网上浏览、询问中介等。\n\n","slug":"chat/23年想在沈阳买个房，想听听大家建议?","date":"2023-02-08T09:23:23.396Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"10f317cd1d4a05e4e7387dd584117d06","title":"如何评价文本编辑器Helix Editor?","content":"如何评价文本编辑器Helix Editor? Helix Editor是一款简单易用的文本编辑器，功能强大，界面美观，支持多平台使用。它支持多种文本格式，包括HTML、CSS、JavaScript、PHP、C/C++、Java、Perl、Python等。它还具有语法高亮、代码补全和校正的功能，可以帮助开发者快速定位代码错误。此外，它还具有测试和调试的功能，可以帮助开发者快速调试文本代码。总之，Helix Editor是一款优秀的文本编辑器，为开发者提供了很多便利。\n","slug":"chat/如何评价文本编辑器Helix Editor?","date":"2023-02-08T09:21:26.559Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"cab5e87d614d2b0e349d86d76ade36ee","title":"护眼显示器怎么选?","content":"护眼显示器怎么选?护眼显示器怎么选?  \n\n光源：尽量选择 LED 背光技术，能够有效降低蓝光辐射，减少眼睛疲劳。\n\n屏幕分辨率：分辨率越高，图像显示的细节就越丰富，也可以减少眼睛的疲劳。\n\n画面亮度和对比度：画面亮度要适中，不要过亮或过暗。对比度也要适中，不可过低或过高。\n\n刷新率：120Hz 或 144Hz 的刷新率可以显著减少眩晕感。 \n\n色彩校正功能：一些高端显示器都会配备色彩校正功能，可以根据不同的使用场景进行调整。\n\n\n","slug":"chat/护眼显示器怎么选?","date":"2023-02-08T09:07:20.707Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"护眼显示器怎么选?护眼显示器是一种特殊的显示器，具有良好的色彩温度、亮度及视角等多方面的优势，既能舒适地保护用户的眼睛，又能满足用户对画面效果的要求。因此，在选择护眼显示器时，应该仔细考虑各个方面的重要性。\n\n显示效果：显示效果是最重要的因素之一。一般来说，一台好的显示器要具备高分辨率、广色域、准确的亮度、对比度和色彩饱和度。\n\n抗眩光功能：大多数护眼显示器都有内部安装了过滤眩光功能。这样可以有效减少对人体的伤害，使得你在使用时更加安心。\n\n电子书阅读：如果你是专门为了读电子书而选购显示器，那么你应该注意准内选购具有特定功能的显示器。这些特定功能包含“夜间”或者“少量光”功能来保障看书时不会刺伤眼球。\n\n舒适性：在考察一台显示器时，你还要注意其中是否有特别注重人体工学的优化功能。如常用的PIP、PBP、OSD、OSD旋钮以及VESA标准壁装托板都是正常情况下必不可少的必备功能之一。\n\n价格：价格也是不容忽略因子之一。根据你所需要使用到相应功能去逐步考察并比价即可找到合适且性价比高的产品。\n\n\n总之, 在选择一台好的护眼显示器时, 要注意得到相关信息并法家性得进行衡量, 不仅要考察他具备相关性能, 还要 机械键盘的轴可以分为红轴、黑轴和茶轴三种，每种轴的手感和声音都不一样，因此，选择哪种轴是完全看个人喜好。 \n一般来说： \n\n红轴是最常用的键盘轴，它具有比较流畅的手感，释放力度也不大，因此是新手最佳选择。 \n\n黑轴具有流畅的手感，释放力度也不大，但声音会比红轴要大一些。 \n\n茶轴具有流畅又有弹性的手感，声音也很小，适合老手使用。 \n\n\n总之，要想选择合适的机械键盘类型，必须根据个人习惯、使用习惯和价位来决定。\n机械键盘红轴与茶轴选那种轴好？一般来说，机械键盘的红轴和茶轴都有各自的优势和特点。红轴主要以快速反应、反射性好而闻名；而茶轴则具有减震效果，能够带来更好的手感。因此，根据使用场景的不同，可以根据实际情况选择不同的机械键盘。如果是要用于快速打字和编写文章，则可以考虑使用红轴机械键盘；如果是要用于日常浏览或者进行大量敲击（尤其是大量无意义敲击）时，则可以考虑使用茶轴机械键盘。\nVim的插件align如何让文本快速左对齐?Vim中align这个强大的工具可以帮助你快速左对齐文本。它能够将文本中不同行之间的特定字符(例如: 冒号、等号、注释符)对齐在一行上。下面是一个例子: \na = 1;  // Set a to 1.\nb     = 2;  // Set b to 2.\nc         = 3;  // Set c to 3.\nd             = 4;  // Set d to 4.  \n\n使用:Align=命令将上述文本左对齐如下:\na = 1;      // Set a to 1.\nb = 2;      // Set b to 2.\nc = 3;      // Set c to 3.\nd = 4;      // Set d to 4. vim的插件align如何让文本快速左对齐？\n\n","slug":"chat/机械键盘红轴与茶轴选那种轴好","date":"2023-02-08T08:58:43.146Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"3830ddd8671d10af2c2e8efa9d9df758","title":"PDF文件转换成Docx文件","content":"测试一下普通不带格式， PDF格式的文件，是否可以转换成Word的Docx文档。 \n本地做PDF到Docx转，在线版的工具有大小限制，本地版本的软件要充会员，所考虑使用一个不花钱的方案。\n安装Libreoffice\n12brew info libreofficebrew install  libreoffice\n\n\n\n执行格式转换的命令行工具。\n1soffice --headless --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 97&quot; keyboard.pdf\n\n\n常用的格式转换的过滤器。 \n12345678910111213141516soffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;Microsoft Word 2007/2010/2013 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to odf:&quot;writer8&quot; a.pdfsoffice --infilter=&quot;writer8&quot; --convert-to doc a.odfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 95&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 97&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;StarOffice XML (Writer)&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;MS Word 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 2007 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;MS Word 2007 XML Template&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;MS Word 2007 XML&quot; a.pdfsoffice --infilter=&quot;Microsoft Word 2007/2010/2013 XML&quot; --convert-to doc a.pdf\n\n\n用 户手册\n测试一下Obsidian插 \n","slug":"zhihu/PDF文件转换成Docx文件","date":"2023-02-08T02:16:55.394Z","categories_index":"文章","tags_index":"linux,libreoffice,pdf","author_index":"安全书"},{"id":"215cb91469bd38dda95988a097965be0","title":"Pandoc快速转换Word到Markdown文件","content":"Pandoc快速转换Word到Markdown文件\n\n\n\n\n\n\n\n\nExcerpt\n\nPandoc快速实现Word转Markdown，Web服务器上HTML转Markdown\n\nPandoc是一款非常强大的文档格式转换工具，对于Word转Markdown的场景，可以快速的实现转换，并且把Word文件中图片，生成到指定的文件夹中。 \n\n\n\n\n\n\n\n\n\nPandoc是由John MacFarlane开发的标记语言转换工具，可实现不同标记语言间的格式转换，堪称该领域中的“瑞士军刀”。\nPandoc understands a number of useful markdown syntax extensions, including document metadata (title, author, date); footnotes; tables; definition lists; superscript and subscript; strikeout; enhanced ordered lists (start number and numbering style are significant); running example lists; delimited code blocks with syntax highlighting; smart quotes, dashes, and ellipses; markdown inside HTML blocks; and inline LaTeX. If strict markdown compatibility is desired, all of these extensions can be turned off.\n上面是引用的，关于Pandoc的介绍。  \n123pandoc -f docx -t markdown test.docx -o test.md --extract-media ./images\n\n\nWord文档中的图片  \n\nWord文档  \n\n转换后的Markdown文件\nPandoc还支持，直接通过Http协议访问网页的内容，并生成Markdown文件，远端Web服务器上的图片也可以，保存到本地的图片文件夹中。 \n123pandoc -f html -t markdown --request-header User-Agent:“Mozilla/5.0” https://candylab.net/design/HFishSOC/ -o candylab.md --extract-media ./images1\n\n\n网站上的HTML  \n\n保存到本地的Markdonwn文件\n方便的地方在于，Word中和图片和网站上的图片，统一保存到指定文件夹中。\n\n内容简介近年来，信息技术的广泛应用极大地促进了社会进步，也方便了人们的工作和生活，随之而来的网络安全问题日益突显。如何构建安全可靠的网络环境，如何与时俱进地把新技术纳入网络安全防护的实践当中，成为网络安全工作者的重要课题。本书聚焦于 Web 服务常用的安全技术，以案例形式展示 Web 服务所面临的威胁，并给出了丰富多样的解决方案。本书由浅入深地介绍了 Web 安全的相关主题，包括 Web 应用程序基础理论、Web服务器与负载均衡、HTTPS和CDN的安全问题、Web服务的安全因素、如何保护Web服务、WAF原理与实践、Web日志审计、蜜罐技术、大数据时代的Web安全、网络安全解决方案等内容。本书适合网络安全领域的研发人员、运维人员、高校师生、培训机构等群体阅读参考。\n","slug":"zhihu/Pandoc快速转换Word到Markdown文件","date":"2023-02-07T08:12:26.159Z","categories_index":"文章","tags_index":"","author_index":"安全书"},{"id":"079e6baebd5d8e475a537e84c2a1db36","title":"萌新的第一把机械键盘，请问罗技g610和ikbcC210怎么选择呢？","content":"萌新的第一把机械键盘，请问罗技g610和ikbcC210怎么选择呢？\n\n\n\n\n\n\n\n\nExcerpt其实这两款都行，主要还是看你眼缘。逻技系列和cherry很像，就是键盘在模具方面都有自己的设计， 还多了…\n\n其实这两款都行，主要还是看你眼缘。\n逻技系列和cherry很像，就是键盘在模具方面都有自己的设计， 还多了键子，或是加了一些控制键。\n玩游戏罗技友好，但是我要说的是，其实这两个键盘没有那么大差异，但是有一个容易被忽视的问题。\n问题就是你：你换键盘帽吗？如果你键帽，你会发现罗技的键帽真的以后换键帽有点问题，罗技的键盘呢外型设计风格有自己的特点， 但是说换键帽真的是，不在好搭配，就像典型的历史上的Cherry g80-3800这种键盘， 最后感觉换配啥键帽都不好看，这个就比较麻烦， 买键盘某种程序上都想让键盘好看，但你看g610这个外型设计。\n\n之前前几年，PBT键帽没有现在这么花哨，就是从阿米洛、akko这波带起来的， IKBC也开始做各种键帽主题，这草其实不好拔，如果你铁了心，以后就不想换键帽，一起玩游戏， 罗技g610没没毛病， 至于那些什么音量控制的特殊键，其实别的键盘也可以通过组合键来完成。\n有人说Cherry轴现在版本的弹簧声点，是有这个想象，但同时也有一个问题，也不是其他的啥国产轴都行， TTC，BOX这种的是可以。\n而大厂产品线比较全的，其实能用手数过的，cherry、罗技、IKBC、雷蛇、包括灯厂的。\n500元的价位，每个品牌都有自己特色的型号,依次说一下：\nCherry樱桃机械键盘500元要是在以前，基本是g80-3850红轴，以前红轴的贵。g80-3000青茶黑轴， g80-3494不行，过了500元这个预算，因为产品升级，不推荐买上一代产品了， 除了g80-3494意外，如果好这个手感和 外观还可以继续买， 现在500元左右，还得是mx 2.0s和3.0s。\n3.0黑色背光版可以， 白了不行，过预算了。\n背光版要贵一些， 全键盘的cherry就推荐上面这两款，主要是工业设计可以，但是配键帽也和罗技一样， 因为他们都太有自己的特点了。\n罗技机械键盘现在特价479就可以入手，最开始都是原厂大家买买买，这些年逻技术的机械键盘整全的系列全了以后，大家对罗技的认可度也高了，但是罗技的轴也就那样。\nIKBC机械键盘IKBC的C系列太经典， 以至于我现在敲文字这段，用的就是C87键盘， IKBC经过市场和用户长时间的考研， 感觉活动价的时候，基本属于闭眼入系列。但游戏的不光是C系列，其实R系列也可以。\n以前的Cherry主题键帽没有现在这么多，基本就是黑白三元色，今年的高达和巧克力系列真的让原本低调朴素的IKBC也玩起了联名款了。\nIKBC基本属于各方面都中规中矩的产品，对得起这个价格，但是不能拿那和阿米洛和F和L比，游戏要用有线有，其实还有W系列的，就是把有线变成2.4G蓝牙的。\n雷蛇机械键盘雷蛇就是做游戏键盘的，特别是他们家自己的轴体，好坏先不说，主要就是他自己的独特生，要是有人就好这个手感，其实也没啥可聊的，就买就行了，今年最火的，感觉还是她的鼠标新出的，而不是键盘。\n经典的不能再经典系列，没啥可说的，就是活动价格100元以内买就行了，我桌子上放了两个。\n今年最猛的鼠标。\n主要还是说键盘，黑寡妇有点过预算，但看着顺眼，入也不是不行，毕竟多少也就100元的事， 以后玩个顺心，看着舒心，能用上几年。\n美商海盗船灯厂的这个红色的背光和雷蛇的绿色背光，简直就是对比色的干活，玩灯还得是灯厂，但是稳定型和质量，其实感觉不一定比以上面的强多少。\n以上凡是有自己膜具设计的厂商，其实配键帽都有点问题，就是IKBC这大众脸的设计，反倒是怎么配都行。从功能性上来说，以上这些品牌其实，也都是大差不差，如果主要使用场景是游戏，其实还是选罗技和雷蛇、海盗船，如果游戏办公兼顾，IKBC和Cherry，如果玩键帽，我建议还是IKBC。\n","slug":"keyboard/萌新的第一把机械键盘，请问罗技g610和ikbcC210怎么选择呢？","date":"2023-02-07T04:12:40.936Z","categories_index":"文章","tags_index":"键盘（计算机）,机械键盘,电脑外设,Cherry（键盘）,机械键盘选购","author_index":"安全书"},{"id":"d06a4cd12369811f5165d02977d7c5f7","title":"OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？","content":"OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？\n\n\n\n\n\n\n\n\nExcerptVSCode的Open AI插件ChatGPT，直接用VSCode进行，找Bug、优化、单体测试等操作。能不能取代搜索引擎？当…\n\nVSCode的Open AI插件ChatGPT，直接用VSCode进行，找Bug、优化、单体测试等操作。\n![](\n\n![](\n\n\n\n\n\n\n940ef5c)e=1940ef5c)\n\n\n![](\n\n\n能不能取代搜索引擎？\n\n\n\n\n\n\n\n\n\n当被问及ChatGPT是否会取代传统的搜索引擎时，奥特曼说：“我不认为ChatGPT会（取代搜索）。但我认为有一天，某个人工智能系统可以。不过，我认为，如果你只关注昨天的新闻，就会完全错过机会。我对思考搜索之外的东西更感兴趣。我不记得我们在网络搜索之前做过什么，我有点太年轻了。”他说，他对这些人工智能模型感到兴奋的原因是，它不是关于“你如何取代上网和输入搜索查询的体验”，而是“我们做什么是完全不同和更酷的？”\n能不能取代程序员？\n\n\n\n\n\n\n\n\n\n在内部对比中，谷歌询问了两个聊天机器人 ChatGPT 和 Alphabet 子公司 DeepMind 的编码引擎 AlphaCode 是否会取代程序员的问题。AlphaCode 曾悄悄潜入 10 场编程比赛敲代码，成绩超过了一半的程序员。“不，ChatGPT 和 AlphaCode 不会取代程序员，”LaMDA 回答道，随后它进行了解释，原因包括“编程是一项团队运动”，虽然聊天机器人“可以帮助程序员更高效地工作”，但它“不能取代伟大项目所必需的创造力和艺术性。”ChatGPT 的回应类似，表示“ChatGPT 或 AlphaCode 不太可能取代程序员”，因为它们“无法完全取代人类程序员的专业知识和创造力……编程是一个复杂的领域，需要对计算机科学有深刻的理解原则和适应新技术的能力。”此外，谷歌还做了一些对比。比如当被要求以 Wes Anderson 的风格以“一个高档商店扒手在一家香水店里被保安审问”为背景，编写一个诙谐有趣的电影场景。LAMDA 以脚本形式编写，而 ChatGPT 以更长、更深入的叙述形式编写。\n","slug":"zhihu/OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？","date":"2023-02-07T03:31:39.634Z","categories_index":"文章","tags_index":"互联网,失业,程序员求职,OpenAI,ChatGPT","author_index":"安全书"},{"id":"7d228d73be79610e7c1c5cb3159d1260","title":"用Rbenv创建Ruby虚拟环境","content":"用Rbenv创建Ruby虚拟环境\n\n\n\n\n\n\n\n\nExcerpt一些测试工具，很多都是Ruby实现的，这些工具可能会要求在不同的Ruby版本下才能兼容运行，所以用一个Ruby虚拟管理工具很必要，就像Python用的Conda， Rbenv就是这么一个工具。 我们在 http://Coding.net 的WEB IDE…\n\n一些测试工具，很多都是Ruby实现的，这些工具可能会要求在不同的Ruby版本下才能兼容运行，所以用一个Ruby虚拟管理工具很必要，就像Python用的Conda， Rbenv就是这么一个工具。\n我们在http://Coding.net 的WEB IDE里创建一个Ruby测试工具环境， 用的是Web IDE的 All In One环境, 之前应该有Ruby环境支持， 经过http://Coding.net的各种Web IDE迭代后不支持了，装一个就行了。Web IDE中自带的Ruby是3.x 版本，有些应用是运行不了的。\n如果是Mac系统安装比较简单，但是http://Coding.net Web IDE是2H 4GB的Ubuntu用apt-get安装，因为是默认的ZSH，有些Bash Shell不太适合,比下下面这种。\n123$ echo &#x27;export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrc$ echo &#x27;eval &quot;$(rbenv init -)&quot;&#x27; &gt;&gt; ~/.bashrc$ exec $SHELL\n\n直接用apt-get安装。\n12apt-get updateapt-get install rbenv\n\n这里要注意一点， 默认安装ruby-build是老版本的，造成很多新版本的ruby环境没法装，这个时候需要把ruby-build卸载了。\n1apt-get remove ruby-build\n\n然后，用Git下载的方式安装。\n1git clone https://github.com/rbenv/ruby-build.git &quot;$(rbenv root)&quot;/plugins/ruby-build\n\n这样，再查看ruby-build的版本就变成了较新的版本，可以到找到类似ruby 2.7的安装包。\n\n\ninstall.sh\n记录运行插件目录下的install.sh，ruby-build才算安装成功。\n12ruby-build --versionruby-build 20221225\n\n\n\nWeb IDE\nruby-build安装成了，再安装各种版本的Ruby才好用。\n\n\n列出可安装的ruby环境\n\n\ndefinition\n查看所能支持的ruby安装版本\n1ruby-build --definition\n\n\n\n查看安装的子版本\n查看目前装了那些ruby子版本\n1rbenv versions\n\n\n\n恢复回默认版本\n安装指定版本的ruby比较快。\n1rbenv install 2.7.1\n\n当然也可用另一种方式安装，但是因为ruby-build支持，没有必要(备用)，比如，如下方法。\n123wget -q https://cache.ruby-lang.org/pub/ruby/2.7/ruby-2.7.1.tar.bz2  -O ~/.rbenv/versions/ruby-2.7.1.tar.gzenv RUBY_BUILD_MIRROR_URL=file:///root/.rbenv/versions/ruby-2.7.1.tar.gzrbenv install 2.7.1\n\n安装后，我切到新到 2.7.1版本。\n\n\n切换到指定版本\n12rbenv global 2.7.1eval &quot;$(rbenv init -)&quot;\n\n因为是Web IDE是Zsh，需要在~/.zprofile 如果shell用的是zsh, eval “$(rbenv init -)” 这句要放到 zprofile中。\n\n\n.zprofile\n如果用的是Bash就放到Bash的配置文件中，这样开新终端的时候，ruby就跳到虚拟环境中。\n","slug":"zhihu/用Rbenv创建Ruby虚拟环境","date":"2023-02-06T07:29:06.264Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"3e5e0ad875e008f2f5596d741d0ac42f","title":"HFish蜜罐与SOC安全运营中心","content":"HFish蜜罐与SOC安全运营中心\n\n\n\n\n\n\n\n\nExcerpt作者：糖果\n\n0x01 传统蜜罐传统蜜罐在安全运营当中，起到防御与威胁发现的作用。蜜罐系统提供Web（WordPress等）服务模拟、及各种主机服务模拟，比如：ElasticSearch、FTP、Telnet、Redis等。 类似FTP、Telnet等高交互蜜罐，不只是开放各种协议服务的端口监听，还真实的模拟的服务用户的交互逻辑，当攻击者访问蜜罐仿真的服务，蜜罐系统会像真的用户访问FTP、Telnet服务一样， 响应用户的操作。\n0x02 反制与溯源随时蜜罐技术迭代发展，从传统蜜罐、高交互蜜罐、 发展具有成高阶形式功能的，具有反制溯源、欺骗防御、主动防御的综合服务仿真蜜罐信息系统。 构建安全防御系统，需要各种安全工具链提供支持，蜜罐系统是安全防御工具链中重要的工具，选用几款优秀的蜜罐系统，应用于安全运营实践过程，对防御工作很必要，蜜罐可以分别部署于内、外网环境当中，这一次介绍的是HFIsh。 在攻击的过程，蜜罐系统会接收攻击者的攻击输入信息，包括攻击用的系统及工具的信息，攻击者可能暴露的个人信息，可溯源反制的蜜罐系统，会根据这些信息，进行攻击者身份信息的关联溯源，根据攻击者系统工具的信息，实施基于对方可能存在漏洞的反制攻击。 如果攻击者可暴露给蜜罐系统的输入数据，不够充分有效，反制溯源就比较困难。\n0x03 蜜罐与防御体系融合HFish\n以HFish构建的蜜罐系统为例，下面是HFish蜜罐系统在实践过程中，一个系统关联图。\n\nHFish是一个具备典型新型蜜罐特征的蜜罐系统，同时提供、低交互、高交互、反制溯源功能。 蜜罐系统属于安全系统中的一个子系统，在安全运营过程中， 需要将蜜罐系统与整个安全防御体系进行融合，将蜜罐系统、TDP流量分析系统、SIEM事件管理系统、SOC运营系统进行协同，最后成为整SOC安全运营系统功能的一部分，与更多防御信息系统进行协防，比如HIDS系统等。 TDP：TDP和HFish同出一家，TDP是流量分析系统，同时提供HFish的接入功能，在HFish相对早期的版本，我们将HFish接入到TDP系统，尝试让HFish威胁日志接入数据库集群，并在某些安全活动使用。TDP对接HFish，接入数据是蜜罐威胁事件日志，并提供蜜罐结点的威胁的攻击统计、威胁事件告警检索功能。接入蜜罐日志后，并不将威胁日志中的IP与威胁情报进行关联，与威胁情报的关联，是在接入日志之前就完成了，所以需要在HFish中接入IP信誉库API。\n\nIP信誉库：在实践的过程中，蜜罐系统与HIDS系统，在判定IP的威胁时，用了同一套IP信誉库，与TDP不同的是， TDP有本地的威胁情报库，会远程下拉同步威胁情报，所以也没有查询上限的限制， 而其他系统需要通过API来完成IP研判工作，没有本地的威胁情报库，有API每天的调用上限次数限制。\n0x04 事件管理与运营管理SIEM：威胁事件管理系统用来处理，TDP接入的蜜罐威胁事件日志， 由TDP转发给SIEM或者，由HFish直接发给SIEM，蜜罐威胁日志成为多条威胁数据管道处理中的一条支流处理分支，然后由SIEM与SOC进行后续的交互，进行威胁的收敛研判。 \nSOC：安全防御信息系统中，有众多的子系统，SIEM通过数据管道完成威胁事件的聚合管理、数据的中继外发、威胁事件数据提供，SOC的一项功能是，完成威胁事件的收敛工作，并建立收敛后的事件与响应流程的联系， 产出可以是建立响应处理提案、各种形式的告警（邮件、群机器人等）、可视化统计、威胁定位检索等。\n0x05 蜜罐联动实践微步在运营HFish之后，HFish不断在升级，各防守单位人员，也加入使用的HFish蜜罐的用户中，配置要求低，上手快，还有可视化大屏幕，支持常见的蜜罐服务和一些比较新威胁服务模拟检测，与威胁情报社区联动，流量分析平台联动。HFish可以与SIP、X社区的联动，使用社区的威胁情报查询Key，进行威胁溯源，还可以与自家的流量威胁检测服务产品TDP进行联动。与TDP的联动最开始因数HFish的输出字段不确定，造成正则不确定，没法正确识别，HFish推送给TDP的告警，但后期这个问题都解决了。包括从本地数据库，迁移到使用云上MySQL也是没问题的，这样相当于分布式蜜罐的报警，可以聚合在TDP流量分析平台上，本地数据都放到云的MySQL上做集中管理。\n\n添加X社区的威胁查询APIKey与IP信誉库进行关联。\n\n申请的API有又上的权限。 \n大屏幕与TDP的4种视角不同，只有一种模式，但是看着还是很直观的。\n\nHFish支持分布式部署管理，支持与X社区联动，取威胁情报，支持与TDP流理分析平联动，关联攻击IP在内网的所有威胁事件，全流量网络连接分析，这些特性是别的单体蜜罐做不到的，提供的服务要比一般的蜜罐，不能与威胁情报联动，不能与流量分析平台联动相比，功能更丰富立体。下面是HFish提供的蜜罐服务，比之前模拟的服务要多很多，而且很接地气，基本覆盖了常见漏洞服务。\n\nHFish还提供威胁风险的检测识别能力，并且可以自己通过YARA，进行自定义检测规则的编写。\n自己在蜜罐后台上，创建检测规则。HFish与流量分析平台TDP联动 HFish可以将蜜罐的告警发送给TDP，进行威胁聚合，威胁关联。用户可从选择只看攻击蜜罐告警信息，也可以在TDP蜜罐监控界面，查看网络流量中，攻击蜜罐的源IP，所有的威胁事件告警信息，威胁情报，威胁名称等等。\n\n蜜罐上呈现是那些IP攻击了蜜罐，而TDP上可以展现出，攻击蜜罐的IP，在内网所有的威胁事件的信息，全流量通信信息。\n\nHFish蜜罐接入到TDP，需要创建一个数据接受监听，并通过正则进行解析，这个正则是随着HFish输出字段的明确，最后固定下来了的。\n0x06 总结所有子系统的威胁事件管理，可以类似HFish蜜罐接入SOC系统一样，将安全运营人员对蜜罐高频操作的威胁确认、统计、等高频常用工作，融合到SOC 系统中，形成子威胁系统在SOC系统中，对应安全运营角色（蜜罐操作者）的工作流程，不用登录蜜罐子系统，在SOC中集中完成蜜罐相关的安全响应处理工作。\n","slug":"candylab/soc","date":"2023-02-03T08:57:22.820Z","categories_index":"文章","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"\nlayout: blogbook: falseistop: truetitle: Lua的变量 – LUA教程background-image: /images/attandck/Pastedimage20211111101818.pngcategory: 文章created: 2023-02-03T16:58:50 (UTC +08:00)tags: [LUA教程]source: https://lua.ren/lua_guide/lua%E6%95%99%E7%A8%8B/variables/author: 糖果\n\nLua的变量 – LUA教程\n\n\n\n\n\n\n\n\nExcerptLUA教程:Lua是一门精巧的语言，与其它语言配合使用，发挥更高的效能。特别是与C和C++语言的配合。著名的项目Openresty就是使用了Lua。\n\nLua的变量变量变量就是给一块内存区域赋予的一个名字。变量使得在程序中就可以修改或读取相应的内存区域中的内容。它可以代表各种不同类型的值，包括函数与表。\n变量的名字由字母、数字与下划线组成。它必须是字母或下划线开头。由于 Lua 是字母大小写敏感的，所以大写字母与小写字母是不一样的。Lua 中有八种基本值类型：\n在 Lua 语言中，虽然我们没有变量数据类型，但是依据变量的作用域我们可以将变量分为三类：\n\n  全局变量：除非显示的声明一个局部变量，否则所有的变量都被默认当作全局变量。\n  局部变量：如果我们将一个变量定义为局部变量，那么这么变量的作用域就被限制在函数内。\n  表字段：这种特殊的变量可以是除了 nil 以外的所有类型，包括函数。\n\nLua 变量定义一个变量定义就意味着告诉解释器在什么地方创建多大的一块存储空间。一个变量定义包括一个可选的类型( type )以及该类型的一个或多个变量名的列表，如下所示：\n1type variable_list;\n\n其中，type 是可以选择指定为 local 或者不指定使用默认值 global，variable_list 是包含一个或多个由逗号分隔的标识符名字。下面是合法变量定义的示例：\n123local    i, jlocal    ilocal    a,c\n\nlocal i,j 声明定义了两个变量 i 与 j；它命令解释器创建两个名称分别为 i,j 的变量，并且将其作用域限制在局部。\n在声明变量的时候可以同时初始化变量（为变量赋初值）。在变量名后跟上等号和一个常量表达式就可以初始化变量。如下所示：\n1type variable_list = value_list;\n\n一些例子如下：\n123local d , f = 5 ,10 --声明局部变量 d，f。 d , f = 5, 10;      --声明全局变量 d，f。 d, f = 10           --[[声明全局变量 d，f，其中 f 的值是 nil--]]\n\n如果只是定义没有初始化，则静态存储变量被隐式初始化为 nil。\nLua 变量声明正如在上面例子看到的那样，为多个变量赋值就是在变量列表后跟上值列表。例子 local d，f = 5，10 中,变量列表是 d，f，值列表是 5，10。\nLua 赋值时会将第一个值赋给第一个变量，第二个值赋给第二个变量，依次类推。所以，d 的值是 5,f 的值是 10。\n示例下面的示例中，变量被声明在顶部，但是它们在主函数中定义和初始化:\n12345678910111213-- 变量定义:local a, b-- 初始化a = 10b = 30print(&quot;value of a:&quot;, a)print(&quot;value of b:&quot;, b)-- 交换变量的值b, a = a, bprint(&quot;value of a:&quot;, a)print(&quot;value of b:&quot;, b)f = 70.0/3.0print(&quot;value of f&quot;, f)\n\n上面的代码被编译生成和执行后，会产生如下的结果：\n12345value of a:10value of b:30value of a:30value of b:10value of f23.333333333333\n\nLua 中的左值与右值Lua　中有两种表达式：\n\n  左值：引用内存位置的表达式被称之为左值表达式。左值表达式既可以出现在赋值符号的左边也可以出现在赋值符号的右边。\n  右值：术语“右值”指存在内存某个位置的数据值。我们不能为右值表达式赋值，也就是说右值表达式只可能出现在赋值符号的右边，而不可能出现在赋值符号的左边。\n\n变量属于左值表达式，所以它可以现在赋值符号的左边。数值常量属于右值表达式，它不能被赋值也不能出现在赋值符号的左边。下面是合法的语句：\n1g = 20\n\n但是，下面的语句是非法的，它会产生生成时错误：\n110 = 20 \n\n在 Lua 语言中，除了上面讲的这种赋值，还允许在一个赋值语句中存在多个左值表达式与多个右值表达式。如下所示：\n1g,l = 20,30\n\n在这个语句中，g 被赋值为 20，l 被赋值为 30。\n","slug":"lua/lua变量","date":"2023-02-03T08:47:16.312Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"aaf5766099e8206fd4b43f584166f61e","title":"编译C++项目使用OpenSSL库","content":"OpenSSL\n一些C/CPP项目，在代码中使用HTTPS协议访问网站，需要使用OpenSSL的.h原文件和SSL库，在编译的时候需要连接这两个资源。 \n在Mac OS上，默认安全的不是通常意义上的开源的OpenSSL， 需要我们手动通过brew进行安装。\n1brew install  openssl\n\n\n在CPP编译时要指明.h的位置和库文件的位置。通过-I和-L两个参数。 \n查看OpenSSL的.h文件位置、库文件的位置，使用命令，如下：\n1brew info openssl\n\n\n我们用一个CPP项目，开展示编译参数的使用。 \n1git clone https://github.com/AntiSomnus/iDict-cmd.git\n\n\ng++ -Os -m64 -std=c++14 idict_linux.cpp -o idict -lssl -lcrypto -v $LDFLAGS\n为了让主程序连接时，可以找到OpenSSL的-lssl这个参数，对应的库文件，加了$LDFLAGS这个参数。这个参数等同于，如下：\n1-L/opt/homebrew/opt/openssl\n\n这路径通过brew info openssl查看，结果类似，如下：\n12345678910111213141516171819202122232425262728293031323334==&gt; openssl@3: stable 3.0.7 (bottled) [keg-only]Cryptography and SSL/TLS Toolkithttps://openssl.org//opt/homebrew/Cellar/openssl@3/3.0.7 (6,454 files, 28.0MB)  Poured from bottle on 2023-01-13 at 11:02:26From: https://github.com/Homebrew/homebrew-core/blob/HEAD/Formula/openssl@3.rbLicense: Apache-2.0==&gt; DependenciesRequired: ca-certificates ✔==&gt; CaveatsA CA file has been bootstrapped using certificates from the systemkeychain. To add additional certificates, place .pem files in  /opt/homebrew/etc/openssl@3/certsand run  /opt/homebrew/opt/openssl@3/bin/c_rehashopenssl@3 is keg-only, which means it was not symlinked into /opt/homebrew,because macOS provides LibreSSL.If you need to have openssl@3 first in your PATH, run:  echo &#x27;export PATH=&quot;/opt/homebrew/opt/openssl@3/bin:$PATH&quot;&#x27; &gt;&gt; ~/.zshrcFor compilers to find openssl@3 you may need to set:  export LDFLAGS=&quot;-L/opt/homebrew/opt/openssl@3/lib&quot;  export CPPFLAGS=&quot;-I/opt/homebrew/opt/openssl@3/include&quot;For pkg-config to find openssl@3 you may need to set:  export PKG_CONFIG_PATH=&quot;/opt/homebrew/opt/openssl@3/lib/pkgconfig&quot;==&gt; Analyticsinstall: 333,606 (30 days), 736,709 (90 days), 2,116,153 (365 days)install-on-request: 86,899 (30 days), 300,347 (90 days), 1,318,084 (365 days)build-error: 280 (30 days)\n\n\n这些返回结果中，和.h头文件，库文件，最直接相关的两个参数：CPPFLAGS和LDFLAGS。在编译的时候直接用$进行引用就可以,顺序如下：\n123export CPPFLAGS=&quot;-I/opt/homebrew/opt/openssl@3/include&quot;   export LDFLAGS=&quot;-L/opt/homebrew/opt/openssl@3/lib&quot;g++ -Os -m64 -std=c++14 idict_linux.cpp -o idict -lssl -lcrypto -v $LDFLAGS $CPPFLAGS\n\n\n\n经过如上的操作，在 Mac上编译时用OpenSSL库，就很顺畅了。\n因为用到加解密模块，很多其他的软件，都可能依赖OpenSLL，特别是很多的C/CPP代码项目工程。\n","slug":"blog/openssl","date":"2023-02-01T09:24:51.888Z","categories_index":"文章","tags_index":"OpenSSL","author_index":"安全书"},{"id":"00bd71ac36adab9def7848f7249016dc","title":"手机代理软件","content":"向网友们询问手机代理软件，大家推荐的： proxyman、charless。\n","slug":"blog/proxyman","date":"2023-02-01T09:03:30.029Z","categories_index":"文章","tags_index":"大数据安全","author_index":"安全书"},{"id":"b81e5d0679173671c6afd090f05d79cb","title":"Graylog几种数据格式规范方法","content":"测试一下更新Graylog对数据格式规范有很几种手段，其中最实用的三种:Split、GROK、Regular。\n分割符号(Split)Split：这个不用多介绍，就是利用分隔符切字段，最好理解。\nJSONJSON: JSON格式也是最简单，几乎不用配置，设备发过来JSON格式，直接按JSON格式解开就行了。\nGROK模式GROK：属于模块化，分装了一些现成的正则表达式，相当于给固定模式正则表达式起了别名。\n1%&#123;IPV4:SrcIP&#125;\n通过这个GROK，获取某个字符串当中的IP。\n原则字符串，如下：\n110.10.10.01:5678(test)-&gt;10.10.01.05:1235(test),\n\n结果，如下：\n12SrcIP    10.10.10.01\n\n这其中的IPV4，用的就是GROK。\n正则表达式（Regular）GROK和Split的方法，都有自己的局限，而正则表达式，正弥补这两个方式的解决不了一些细节问题，或者能解决，但是比较麻烦。\n举例，在告警的IOC信息里，找到CVE号。\n原始数据,如下：\n1XXXXXXXXXXXXXXXXXXXXXXX(CVE-2011-5007)XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\n接下来要做的，就是在这个长字符串中，找到：CVE-2011-5007，用如下的正侧表达式实现。\n1(?i)(cve-\\d&#123;4&#125;-\\d&#123;4,7&#125;)\n\n结果：\n1CVE-2011-5007\n\n以上就是几种，比较常见的数所规范化的手段。\n取得[：]之间的数据。由我们自己创建的一些安全策略规则， 在发出的告警日志中，自定义输出的内容格式，比如我们假定要发送部门相关的信息：[DEP:IS]像这种加了标签的数据，也可以用正则表达式进行定位这部分信息字段，[DEP:IS]对应的正则表达式，如下：\n1DEP:(.+?)]\n\n这样就要以提取[DEP:IS]中的内容’IS’。\n如果想输出另外一个标签，比如[DB:MySQL]一样的模式就可以了。  想取出数据库类型，修改一下上面的正则表达式就行了。\n1DB:(.+?)]\n 规则很明显 ， 想加什么标签，在[:]中的:前面加标签名，在:符号加标签属性就行了。 \n创建一条访问域名的suricata规则， 对于访问abc.com域名进行告警。\n下面的代码片段可以帮助你在 Suricata 上创建一条告警规则，用于监测 abc.com 域名的访问并报警：\nalert tcp any any -&gt; $HOME_NET any (msg:”Traffic from abc.com”; content:”abc.com”; http_host; sid:1000001; rev:1;)\n其中，\n\n$HOME_NET 部分表示监测内网中的访问行为。\ncontent:&quot;abc.com&quot; 是用于匹配访问 abc.com 的 HTTP 请求 / 响应头中的域名内容。\nhttp_host 表示只检查 HTTP 请求/响应中的 host 头部。\nsid(规则 ID) 是一个辨识符，用于标识每条规则，便于日后查看这项规则的细节及更新。\nrev表示规则的版本号，在发生了规则调整时将其 +1 即可。\n\n如果你想要对所有访问 abc.com 的端口进行检测，可以将第一个协议 (‘TCP’) 改为 ‘Any’：\nalert any any any -&gt; $HOME_NET any (msg:”Traffic from abc.com”; content:”abc.com”; http_host; sid:1000001; rev:1;)\n测试一下呢 这取决于你要测试的是什么，你想要测试的结果是什么。如果你想要测试一些软件或程序，那么你可能需要使用一些特定的测试工具来运行和记录测试步骤和结果。如果你想\n创建Suricata告警规则，对经过10.210开头的B段IP的所有端口从3000到5000的端口进行告警。 alert tcp any any -&gt; 10.210.0.0/16 3000:5000 (msg:”Alert B segment IP from port 3000 to 5000”;)\n生成下面这段程序的单体测试lua程序function ChatGPT(num1, num2)local ret = num1 + num2return retendChatGPT(5,7) –单元测试\nlocal function test_ChatGPT()assert(ChatGPT(5,7) == 12)assert(ChatGPT(4,4) == 8)endtest_ChatGPT()\nWe Don’t Wanna Make It Without You翻译成中文的意思\n","slug":"blog/regular","date":"2023-02-01T09:03:30.029Z","categories_index":"文章","tags_index":"Graylog,正则表达式,GROK,JSON,Split","author_index":"安全书"},{"id":"402564c39cfb4dc9fb7de384d537a2bc","title":"安全运营项目的工作方法","content":"作者：李瑞\n本文信息量巨大，阅读大约需要二十分钟左右，建议加关注收藏后阅读。\n日常工作中对接研发同学的一次漏洞答疑，写代码优化敏感数据的识别统计指标，处理应急响应，安全BP发起弱口令治理，日常的补丁管理，组织大型的国家级“HVV”专项，都属于典型的安全运营类的项目范畴。\n\n安全运营是工作的一部分我们做了大量的安全运营工作，这些事情以项目论起来有大有小，不同公司对这些从事这些一线运营工作的内容描述有“拿结果”、“push”、”落地”、“打法”、”主导”不同的说法，我比较认可“推动”的说法，通过运营专项推动工作达到预定的治理效果，”推“和”动“很形象地说明关于安全运营的主要工作：需要主动“推一推才动”，安全的特点确实是要做成一件事，合作方确实有很少的意愿去配合，所以需要有科学的办法去运营这些事情。\n零零总总完成工作总是很容易的，但是首先要理解它为什么能完成？顺利和困难是偶然还是必然？是无意做出的决策还是有意遵循了什么逻辑？做到”知其然然后知其所以然“很难，虽然明面上运营这类事情有PMO( Program Management Officer 项目管理办公室)参与协助，但是PMO仅仅是运营项目的支持者和协调者，领域负责人必须承担全部的责任，这就考验为达成安全运营效果所要求的技术能力、沟通技巧和组织能力，参考基层安全管理者需要具备的素质。 \n临近年底组织内经常用运营专项的实施效果来衡量OKR和KPI的完成情况。虽然各种的安全运营专项的是安全部门运营工作的重要组成部分，但是回头看做得好坏并不仅仅取决于技术来实现，也负责人具备一些项目管理和软技能，将安全目标和企业运营逻辑“黏合”起来。 \n本文不讨论任何技术细节，而是以安全行业工作特点为例，系统化思考安全运营的本质，重点从项目角度介绍开展工作的基本功，仅仅是作为“井底之蛙”将浅薄的经验整理沉淀，希望通过同大家交流得到反馈。\n安全工作的逻辑在正式进入对这个问题的分析和探讨之前，我们很有必要整理下为什么我们要做这些安全专项？背后的思考逻辑是什么？公司各个团队是如何运作划分的？为什么分配你负责一个项目？\n安全团队是怎么运作的首先科普将安全作为风险管理的重要概念，各家组织最上级的安全战略决策机构，不管他们叫做什么风险委员会、首席风险官，集团安全办之类的，根据业界最佳实践会为了达到风险治理的目标从组织层面划分了三道防线完成整体安全目标： \n第一道防线是业务部门自己，出现安全风险后，业务是第一责任人，安全团队承担同等责任，业务内部有负责一线研发、对接BP、专职安全测试的人员，保证一线和自己相关的层面不出现问题。\n第二道防线是管理具体风险的专业安全部门。比如各家公司的业务风控和安全部门，也是安全从业者聚集最多的部门，一般划分为数据安全、风控、产品和IT安全多个团队。他们负责隐私保护、安全工具、渗透测试技术和应急响应工单系统等，构成大家最为熟知的安全管理防御战线。\n第三道防线大家直接接触不多，但是有意无意都在配合，指承担审计、测评合规，做合规制度、监督、流程控制活动的部门，一般理解是为了”务虚“，实际上基本代表安全工作的目标。\n那为什么组织内要运营大量安全专项呢？扫帚不到，灰尘是不会自己消失的，各个安全专项通过主动治理完成法律合规、数据安全，配合达成组织要求的战略目标。但是对于将要完成安全运营项目的压力不用自己背，公司在运营层面已经搭建好相关的治理框架，会提供三个成熟的管理体系来支撑：\n风险管理\n风险管理通过风险的识别、改进、度量、处置来管理内外部风险。管理Owasp Top10风险，SRC复盘漏洞工作，日常黑白盒漏洞发现、添加拦截规则等工作。\n运营管理\n运营管理通过指标体系、监督改进、报告度量、绩效考核从运营层面保证组织和人员的投入。比如日常的数据采集分析、运营漏斗模型，同业务沟通反馈风控策略，答疑安全sdk的使用等工作。\n项目建设管理\n项目管理是指某些待建设的专项来支持安全治理，采用项目管理的标准方法论。比如通过改进应用程序设计和基础设施架构提升安全性，例子包括建设一个容器waf、搭建开源kms、制定iot安全审计流程规范、供应链安全管理等。\n公司根据上述的逻辑来划分组织架构，提供保障资源。这个前提开展安全运营工作的基本盘，你所有的合作，沟通，管理、反馈，安全运营涉及的闪转腾挪都是基于这些体系运转的。\n定义安全运营项目参考项目的定义，安全运营专项在组织层面的定义很清楚：由安全团队作为二、三道防线完成风险发现和指导技术和运营，敦促一道业务防线配合，达成安全目标而采取的运营管理要素的总和。说人话就是：除了技术之外，为达成安全的”做事逻辑和方法”，都可以归类为安全运营。\n例子一：发起域控安全加固运营的安全运营项目，那么它有明确和具体的要素：\n\n目标--解决某一领域风险（域系统）\n\n工作范围--风险治理范围（并不仅仅是域控服务器，还包括打印机、exchange服务，但不包括未加入域的机器）\n\n预算和时间质量要求--在攻击者利用之前修复和建设完成，保证无入侵视野盲区。\n\n例子二：入侵检测项目运营\n\n目标：具备入侵服务器的安全监测技术和管理系统\n\n工作范围：IDC和办公网的资产\n\n预算：有限\n\n时间和质量要求：依时间计划阶段性建设基础和纵深防御和感知能力\n\n项目运营的要点但是没有人是主动的“长期主义者”，我们天性很喜欢写个Poc弹出个计算器，但是安全运营一般是以月度、季度和年来计算的，很难像写代码一样马上出true或者false的运营结果（相反运营做得越好，永远不会有风险在真实坏境被体现，越没有正向反馈）。\n那么有什么框架可以帮助大家来梳理思路呢？就像编程有框架和范式一样，安全运营可以参考ISO27001和应急响应IIPDRR（Identify、Protect、Detect、Respond、Recover）的工作方法论，借鉴PDCA循环：通过计划（Plan）、实施（Do）,检查（Check）,处理（Action）来改善工作。\n安全专项首先了解目前的安全问题或风险，对风险进行根因分析，设定目标和计划，分工完成任务，最后对检查任务执行的效果，评估风险现状，不断改进，达到闭环。\n\n图片\n计划的计划为了避免忙于具体事务而疏于运筹，安全运营计划要在实施前提前起草，这并不只是书面的计划，起码要做到心中有数，计划按照过程分为启动、组织准备、执行、结束、评估复盘阶段，计划的内容包括确定阶段划分、交付结果、里程碑、分工、沟通和决策机制和闭环条件。制定的计划要张弛有度，定稿后要公布出去。\n简单的安全运营比如写一段代码提升url去重效率，也可以视为一个黑盒扫描运营中的子类小计划，只是大家平时视而不见，但其实遵循同样的计划的做事逻辑。复杂的安全运营项目的计划和开发、挖掘漏洞相比，不是可以独立加班搞定的，依赖于多个合作方的配合，所以刚启动时最好是有以周为颗粒度的计划，迅速让各参与方独立制定“小计划”配合建立工作节奏。\n\n计划要取得干系人认同干系人是解决问题的关键点，承担安全运营的效果，干系人划分可以参考RACSIC模型：\n谁负责（R = Responsible），负责执行任务的角色，具体负责操控项目、解决问题。\n谁批准（A = Accountable），对任务负全责的角色，只有经其同意或签署之后，项目才能得以进行。\n谁支持（S = Support），参与具体任务，协助R完成工作的角色。\n咨询谁（C = Consulted），在任务实施前或中提供指定性意见的人员。\n告知谁（I = Informed），及时被通知结果的人员，不必向其咨询、征求意见。\n简单说干系人就是做安全运营需要哪些人参与，他们对工作效果有直接的影响，是活生生的人，不是代码，不能被忽视。\n范围划定范围是工作要做那些事的边界，有时候对于要运营的范围存在没说清楚、没想清楚然后工作资源分配不均匀。\n举个例子：理想情况下去评估一个对外采供应商的产品评估安全风险，但是做着做着发现这个外采系统依赖了大量的第三方开源组件，越评估涉及事情越多，这时候要在采购合同担保明确安全责任范围，是将系统作为一个安全管理的整体，还是仅仅关注核心交付软件。\n\n“你无法管理你无法衡量的东西”，没有度量就没有管理，建议在确定工作范围后，第一要务是给出范围内的关键度量评价指标，明确治理的好和坏的评价标准，画出任务统计分析大盘，比如让大家看到一个安全运营的图表，不在横坐标和纵轴坐标的都是工作范围之外。一条优雅的曲线在接下来的工作可以说明很多事情，有些指标事后就不大容易收集得到，难以说清个人在项目中的工作价值。\n风险的风险这里的风险是指对处理”安全风险“中出现的“运营风险”进行管理，在解决这些漏洞威胁层面的风险时，运营方面经常出现项目管控风险，如同解决安全风险一样，影响安全运营项目达成的风险也依赖风险识别、分析、计划、监控的管理手段。一个安全项目的风险主要分为技术、管理、组织、外部四个方面，风险的应对措施也是大家熟悉的规避、转移、弱化、接受策略，项目的风险管理和安全漏洞的风险管理没什么不同。 \n假设要运营一个隐私保护的专项，那么技术“风险”可能是没有相关的隐私和数据安全计算平台、难以落地差分隐私技术、隐私保护技术要求过于超前等技术原因；\n\n管理风险：人力不足，人员都是从数据和业务安全转过来的，不熟悉隐私保护领域；\n\n组织风险:业务领导对隐私保护的优先级和安全给出的判断不一致；\n\n外部风险:《个人信息保护法》和GDPR之间的法律法规关系，业务接口人离职等。\n\n对于外部风险的处置方法你当然可以选择上面的四种策略之一--接受：不用管业务接口人会离职。\n\n运营方案尽量要评审组织一个大的运营项目，如为了解决主机登录问题推广jumper server跳板机在混合云架构，这时候不能片面相信技术可以拿来即用，要关键人参与进来评审，考虑落地时的性能、稳定性、目标。一般情况下质量、成本、时间永远无法达到平衡，改变的魔法是提高生产力，提前准备好靠谱的安全运营项目方案有助于事半功倍，可行性优先于必要性，主动征求他人意见能发现操作层面细节的盲区。\n除了技术方案，涉及到宣传、向上管理、跨部门的汇报也要集体决策，把控运营方案的可行性、普及性，多方配合做到心中有数。\n就像很遗憾在一个安全团队中并没有任何一个完整走SDL流程的产品一样，运营的方案评审总被主动忽略。原则是可以走得稳才能走得远，没有经过调查分析的方案就没有发言权，欢迎大家对方案吵架，吵完架后坚决执行。\n过程的过程实施运营任务时，并不仅仅要为了结果负责，还要保证过程的相对质量。过程的积累很多是文档类型，清晰的运营文档会带来很多优点：\n思考得更清楚，做事的方法论是”Think，Write，Speak，then Do“，你首先要想清楚怎么推行一件事，然后写出来，在写的过程中再次思考，确保你自己明白你要说和做的事情。降低沟通成本，一份有详细数据、附录、FAQ的材料胜过巧舌如簧，这类文档材料包括并不局限于会议材料、方案设计、代码、专项人员联系表、宣传材料。大家基于同一份材料进行争论才不会各说各话，培训和沟通的成本能大幅减低。历史追溯，要面向”离职“工作，以你的任务交接给别人他是否能理解的标准做事，持续运行的严格要求带来过程管理的完善性。良好的记录可以帮助查询当时的背景、决策依据，回忆是不可靠的，录屏、录音没人有耐心分析回溯。文档材料阅读更快，如果依赖当事人的口述通常失真且抓不到重点，过程材料可以搜索、复用、归档、查看历史版本。做到有法可依这里其实是属于项目管理的需求管理范畴，做安全运营隐含着要做的事情得符合制度法规要求，在运营层面可以适当整理、遵循相关的材料，以相关的制度体系作为运营工作的准绳。组织一般会制定四级文件制度，\n最上一层是公司的最高安全战略纲领或者最高安全和隐私政策，这个级别一般在运营层面不会涉及，由大老板去运营。\n二级文件一般是具体的标准和规范，这些材料都是开展工作的依据，如果工作中缺少大量的此类材料，甚至都没有公司层面《web系统上线规范》就要去运营一个web系统架构评审项目，建议补全后再全面实施运营。 \n三级文件是指南、流程、最佳实践之类的材料，，一般专项的负责人可以根据项目的情况发起新增和修改，在这个层面就是“有法可依”，不然治理时容易责任不清楚，或者责任方不清楚运营工作的评判标准是什么。 \n四级文件以模板、报告、汇报材料，就些在工作中涉及比较多，可以多积累作为安全专项的工作手册后续重复使用。细节材料的文档积累比代码更重要。\n一级：比如对于华为的全球网络安全与用户隐私保护委员会，由任正非签发的《关于构筑全球网络安全保障体系的声明》及《华为隐私保护总体政策》就属于一级实践框架。\n\n二级：比如字节跳动的信息安全委员会关联的安全风控部门整体负责信息安全与业务风控的建设、规划和管理工作。那么会有如《今日头条社区规范》，数据安全与隐私保护部门颁发的《字节跳动隐私保护政策》作为二级材料支撑。\n\n三级：比如《上云最佳安全实践》、《公司密码算法术语定义》等。\n\n四级：判断一个设计方案是否符合安全标准的checklist；一个会议沟通纪要等。\n\n如果没有这些材料会出现什么问题呢？比如我们要做一个http鉴权的安全治理，但是缺少公司层面的统一鉴权规范，那么这件事是做还是不做呢？是等着公司出规范指引，还是大家各自问政，使用五花八门的鉴权方案呢？缺少鉴权的二级规范文件，三级的文件自然无法引用，最终业务没有办法就鉴权方案这件事达成一致，安全也不知道该怎么评审现在的BA认证鉴权是否符合安全要求，最终运营项目宣告失败。\n沟通和组织图片\n找到对的人开展工作需要同不同层级的人打交道，就像新上任的CISO需要一张组织架构图、一张IT系统设计图一样，要项目顺利运营要摸清人际和部门的关系，他们分别负责什么，实线和虚线都要了解到。\n比如要做一个“云等保测评”的任务，需要同CIO、IT运营人员、开发人员、合规治理、咨询机构打交道，大家在一起合作任务时，的第一个难题一定是是：我不知道什么问题该找谁？等保测评发现的代码仓库审计日志问题，同一线开发沟通难以配合，但是他的直接上级却能完成配合改正，站位思考不一样。\n\n另外安全是并且只能是”自上而下“。有时候为了方便我们总想绕过流程，做一些“自下而上的事情”达成短期效果，长期来看是错的，虽然此时方便做成一件事情，但是掩盖了流程的混乱和决策机制，不利于建设透明、高效、信任的业务安全文化。\n沟通要明确找到对的人目的是达成沟通，需要与他人合作的运营项目时，我们面对的不再是代码，不是黑客，而是HR、工程技术人员、非安全领域领导，他们没有“读心术”，要大大方方说出来你要他们干什么事情，需要什么帮助，也要谦虚谨慎不懂就问，遇到分歧时耐心倾听，换位思考、坚持原则性问题的同时也要适当妥协，明白对方说话的意义，自己说出来的话也得直指问题本质。\n沟通时涉及要点是并不仅仅是一遍说，有的要求得和业务方反复说，反复澄清，不要高估非安全专业人员的对你要做的事情的理解力。\n汇报要得到决策上级分配给你一个项目时内心是最焦虑的，他从此将没有数据，没有进展，没有好消息也没有坏消息，犹如石沉大海，又如“肉包子打狗”。透明才能高效，汇报的目的是为了决策，经常出现的一个阻碍安全运营效果的事情是从事技术的一线人员对于一个风险处理没有办法做出决策，而有能力做出决策的人没有全面的信息。上级交付给其他人运营任务时，表示委托给你希望得到风险闭环，就不要在临近结束时给上级时不时的“惊喜”，宁可提前消除“期望”，也不要让“希望”破灭。 \n但也不是说事事都需要请示，那是传话筒。影响重大的，没有先例的，拿不准的要事先请示取得一致，有时候形势来不及的，要当机令断，但是要断得符合以往的工作风格，在事后要及时汇报清楚，看能否补救或者双方对齐情况。\n汇报要避免一切顺利的假象，上级的作用是协调资源提供帮助，让他看到目前的风险和应对措施更为重要，要平衡在上级心目中”你办事，我放心“的人设，也是及时汇报相互反馈。\n汇报尽量避免只有会议这一个方法，不然效率太低，尽量通过书面或者简报完成，会议一般有多人参会，你汇报的东西大家并不关心，浪费大家时间。另个原因是汇报应该表示事情实际的进展，如果上级需要得到项目的现状，为什么要等到日程表有空呢，周一发现的问题非要等周五开周会才暴露？\n进度的监控工作的进度依赖于团队的整体能力，技术是其一，大家都熟，管理是其二，需要探索。从项目的角度来看进度一般是难以把控的，只能监控，只有科学监控才能得到项目的准确进展。运营安全专项和写一个项目代码没有什么不同的，我们很熟DevOps的开发效率，需求变更、弹性部署概念，自然也知道实时的告警监控至关重要。进度有偏差是正常的，但是需要知道进度。\n除了自动化开发的指标能反馈项目的运营进度外，编制各种报告也是常见的管理工具，有口头汇报、简报、日周月季度等多种模板，依组织习惯有邮件、文档、IM多种形式。\n简报周报和月报简报是事情发生时帮忙相关人快速理解发生了什么和进度的文字内容。一般包含背景、影响、措施、并定期汇报。周会一般是输出周报，包含上周待办完成情况，工作范围、任务完成情况、问题对策和需要的帮助，还有下周计划。\n月报并不简单是周报的合并，最好对交付的进度设定里程碑目标，里程碑是完成工作的标志性时间，包括时间点、标志性、交付物、关闭条件，一般一个专项有多个里程碑作为checkpoint检查进度，然后调整计划。\n明确闭环标准在安全运营的生命周期里肯定能达成阶段性的效果，比如一个规则的漏报误报率低于30%，XDR基本建设完成，这时候需要结项评估，结项时仅仅比对当时规定的需求范围进行验收。\n不要一个事情永远做不完，明确deadline和验收标准，从不断完成小的专项积累建立成就感，有了信心可以不断尝试做更大的项目，达不到预定目标是正常，这不是背锅，学习型的团队从教训中得到收获，能避免重复犯错误。\n项目集的管理安全项目有其特有的不确定性、曲折性、复杂性、专业性，有时候会有零零总总多个项目齐头并进，互相关联，比如要运营推进一个域控补丁的管理，但是此时ITIL流程系统还未建立。从项目集角度并不仅仅关注工作如何完成的，更关心资源是否得到充分利用。项目集的要素和项目一致，包括整体进展计划，详细进展、里程碑描述、风险和问题。通过透视图、甘特图等工具能一目了然看到有延期和暂停的风险项目。\n平时运营时尽量有一双慧眼能发现新的安全运营点，扩大安全团队盘子避免内卷，孵化新的安全技术项目，然后规划立项到项目集里，尝试”无中生有“锻炼运营能力。\n怎么去开会笔者忙得时候大概每天都有两次以上的会议，不是在开会，就是在准备开会材料，或者落实会议的待办项，但是切实知道干活就得会开会。但是考虑到ROI，尤其是推动大范围的安全运营事项时的多方开会是个高成本的事情，多人开会需要对每个人发开会的工资，而且开会期间他得假装开会，不能做别的有价值的事情，然而实际上大家讨论要解决的安全问题可能并不值得花费举办多次会议的沉没和机会成本。\n开会的第一个要点是安排会议不要超过40分钟，不然大家会玩手机，问题不在参会者，在于时间的控制。人的天性是难以长期集中精力会疲劳，一旦疲劳会议的质量会直线下降，当然一个会议本身这么长已经表示项目出现了问题–之前各方的沟通已经不畅通需要对齐。\n开会的内容一般分为三种：\n运营前：\n核心指标的制定，如果误报率指标定得高了，说明漏报率指标有变动，困难是找到合适的指标，说清楚选取这个指标的逻辑，对应的反向指标是什么；计划在时间和任务上的拆解，是代码维度、应用维度、还是部门维度；如何达成运营目标的策略会议，是采用了新的技术方案，是增加了人力资源去运营专项，明白是怎么样完成工作任务的；如何保证项目进展的指标汇报，是统计大盘，还是通过周会晾晒指标。\n运营中：\n检查进度和质量，通过汇报或者定期会议；发现执行的问题和原因并处理；调整项目运营计划、指标。运营后：\n安全运营效果，进展总结，比如项目建设完成验收；下一步计划制定和调整，比如一个安全方案在内部灰度试点计划完成后的大范围实施计划；复盘和经验总结，比如专项复盘、绩效考核、述职汇报等。\n准备的准备开会是推动事情进展的必须项，但是要顺利达成进展，并不仅仅需要水平和经验，也需要事前周密的考虑和准备，对会议发生的情况和困难要一一想好对策，有了心理预期就比较准备，有了信心才能成事。自己都没有信心，怎么样合作伙伴相信你配合你做事呢？建议在开会前就写好会议纪要，开会就是想办法按照发起人的意愿分派工作，漫无目的的开会是集体划水。\n会前会中会后组织会议的目标是大家达成共识，开会的过程是达成统一思想，求同存异，结果是执行解决会上的问题。开会前收集明确议题、议程、相关材料和沟通好时间，确保关键人参会，要有礼貌”请“人开会而不是通知，因为有些事需要人家点头才能推行。在会下花的时间要多于会上，不要寄希望一次会议产生神奇的效果，所谓“功夫在诗外”，提前要和有分歧关键点达成共识想到解决的办法才能高效会议。\n会中要保持秩序，先说清楚要希望大家决策什么事情，议题含义，然后看材料讨论，要避免发散性的发言。会议保持紧张感是好事，每次发愁开会时当事人才会“如芒在背”传导工作压力。\n会后的待办任务要确保当事人理解任务的含义，要干什么，验收标准是什么，也一定要标注清楚责任人和完成时间。哪怕任务超期未能完成，落在纸面上的东西起码有人重视会给个说法。纪要在发出时找到当事人确认避免有分歧，损失以后合作的公信力。下次会议就首先以上次会议的待办项来开始。\n复盘的复盘\n图片\n复盘是常见的一种会议类型，对一个安全运营效果的复盘可能有SRC漏洞复盘、蓝军渗透测试复盘会议、公司通告等多种形式，一次复盘会议的效果好坏本身也是值得运营负责人总结经验教训的。在攻防层面大家都很菜，工作仓促应战难免有失误，纵深防御么:) 有了失误就追究责任不利于后续工作。复盘不是为了惩处甩锅，而是为了吸取经验教训，找到真正的根因点，尽量下次不犯错。\n虽然按照严格的复盘方法论要“对事不对人”，但是实际中是不可能的，事总是人做的，正是因为这样坦诚复盘机会很难得，要“刨根问底”才是负责任的态度。 \n大部分攻防案例的复盘，讨论到具体事情都是将“资源不足”作为根因，得到这个答案时证明一般没有掌握正确的工作方法–5Why分析，混淆了复盘根因和分配任务项的区别。复盘不应该是这样的，要考虑预期是什么？为什么不符合预期？还有没有别的办法？这些别的措施能阻止事情再次发生吗？复盘不在于问得问题多，而在于深入分析根因。\n举个复盘的例子：问什么客服部门的员工会点击钓鱼邮件输入账户密码，回答是我们没有预算和资源不够，然后列举一大堆原因：没有时间和精力覆盖到每个部门去宣传培训；客服人员流动大；业务部门对安全不重视。那经过培训的业务有没有点击钓鱼邮件？怎么确定培训有效果？人员流动和对安全不重视有什么数据支撑？\n\n也许深层次的根因是培训对于上规模的公司已经成了边际效应，投入更多的培训和宣传预算也阻止不了那么多的员工偶然性的中招，正确的做法不应该是增加培训预算，而是提高止损和发现能力。\n\nPPT和WORD这两类材料是开会或者推动运营工作的重要交付物，共同要求都是内容要精要，布局要精美，写作方法唯有多看材料，多练多思考才能进步。ppt和word各有优劣，看汇报对象是对语言还是文字更敏感。\nPPT好的材料要突出重点，弱化次要的信息，去掉任何无关的信息。有点技术会议上会用表情包那样的PPT，符合年轻人的风格，但是本质还是通过文字来铺排，信息量还是不够突出。好的材料要区分场合。对技术人员的演示可以有精确的描述，完整的具体和段落。但是面向多人的科普可以适当简化，反正会后他们再也不会看材料了：） \nppt作为材料汇报要有情感，看材料并不仅仅有理性思考，还有共鸣产生。在black hat、RSA等国外会议上的一些攻防相关的ppt，你不会记得他的实现细节，但会记得他提出来解决了让大家捉襟见肘的难点，这就是有共鸣相通的，不用花最多时间追求PPT里的花里胡哨，因为逻辑和数据OK，前面“宣称解决了，就是真的解决了，没人在乎”。\n同技术介绍类会议的PPT相比，给领导汇报的PPT的前几页首先不要解释技术难点和业务逻辑，要谈“实现效果”，领导关心取得的业绩成果而不是工作过程。\nWORDWORD的缺陷是不能指望大家逐字逐句去做阅读理解。大家都很忙，有时候大家可能只有在发起人讲开场白的间隙看下目录结构和待讨论内容。要讲结论和待决策内容在前面，然后按照逻辑铺排开来，引申材料放在附件索引。\nWORD的写作站位要放过读者，每个读者都在希望艰涩的技术讨论、可怕的大段代码，陌生的技术名词之间看到自己熟悉的内容：“谢天谢地终于找到我能懂的内容了，看来我不是这间会议室里的傻子”。本文就是在大量的项目管理名词之间穿插了大家日常安全工作的案例，希望你能理解笔者的苦心：）\n案例：不同场景下的五份材料笔者最近观察到一个典型的案例说明不同沟通场景下，对同一个话题，IDC内的零信任，不同沟通材料的底层协作逻辑如何不同。\n从时间顺序上来说首先有这篇文章《张欧：数字银行可信网络实践》，这是作为企业安全负责人角度，讲解内部的建设理念、思路和方案，重点是组织要达成的业绩和实现路径。\n而《ThreatSource：Google BeyondProd安全架构详解》这个PPT讲解的项目从安全架构师角度，同具体的一线开发人员交流技术细节和实现。\n《零信任实践分享》是介绍他山之石，以谷歌员工过来人的角度介绍理论和实践，所以适当忽略技术细节，重点是诠释“经验教训”。\n而《A Touch of BeyondProd》是从给同行分享普及这类技术，区分对各种技术决策的理解WHY，同类方案的选型WHT，要解决的问题和展望HOW。\n材料《生产网零信任，阿里云落地最佳实践》是阿里云安全的宣传文，讲了落地并实践了的什么方案，解决了生产网的隔离问题，给客户以信心。\n不同材料适合不同场景下的阅读人员。比对几份材料就会发现存在明显的异同，而这些材料讲得其实几乎是同一类安全运营项目！\n帮助别人开会参加合作方的会议要展示安全团队的风貌，是宣传安全理念的机会，要团结不要分裂，要阳谋不要阴谋。有时候一个专项任务会分解为多人承担的子任务，比如一个弱口令治理，可能有人负责数据统计分析、有人出技术方案、有人对接合作方“push”进展。专项负责人要尽量参加到这些会议中，哪怕实际手头有忙的事情，你的参会给小伙伴信心，有时候关键的一两句话可以显著推动事情的进展。\n如果小伙伴说错了，不严重的不需要抢过话题去纠正，大家都是在探索尽量靠近运营治理的目标，会后沟通明确下次就有经验了。\n遇到困难怎么办对项目有强烈责任心的人总能发现潜在风险，看得远想得透。遇到困难不要扛着，首先要寻求帮助，要相信团队的力量，个人思考有盲区，多方思考沟通总是能开阔思路。还要积极主动化劣势为优势，在工作中难免有难点，主动提出建设性的想法，先不要摆手推辞，事后有时候看来并没有当初看来那么难。\n项目进行过程中有时候让你生闷气吐槽，有时候让你绝望无助，有时候让你无地自容，不用慌，对于无能无力的事情坦然应对保持健康娱乐心态，合理承受压力稳定军心。\n要坚韧不拔，不达目的不罢休，任何项目只要立项了，只要没人赶你走就坚决不离开，熬着总能有收获。\n写在最后限于篇幅有些章节不能说透，但安全运营的实践同网络安全的特点一样没有银弹，这项工作只有言传身教或者让公司交学费。安全运营也可以很优雅，留给你适当空间可以大胆发挥根据自家的实际情况摸索，总而言之四个字：干就完了。\n在安全行业我们总是逆流而上，同旧世界不断PK，Fighting，工作惯性很强大，知易行难，要想成功需要主动克服痛苦才能引导变革，只有走在追寻更有价值和有意义的路上才能保持竞争优势，创新改变世界，愿读者们长期有耐心，做好一位安全运营的长期主义者。\n参考资料职业欠钱谈安全运营 https://www.zhihu.com/column/c_1161574152535855104\n《数据安全架构设计与实战》https://item.jd.com/12731728.html\n《用图表说话：麦肯锡商务沟通完全工具箱》https://item.jd.com/11324809.html\nPMBOK （美国的项目管理知识体系） https://baike.baidu.com/item/PMBOK/63635\n\n\n声明：转载于公众号《安全乐观主义》\n\n","slug":"blog/sec-operation","date":"2023-02-01T09:03:30.029Z","categories_index":"文章","tags_index":"安全运营","author_index":"安全书"},{"id":"898ea7cfc21533e8cdd79b533fcbfa66","title":"理解威胁情报与威胁数据分析","content":"1、如何理解威胁情报和数据分析在企业安全运营中心建设阶段中我们期望通过汇总大量的安全日志事件分析安全数据和威胁映射。获得攻击者所采用的各种攻击手段特别是遇到鱼叉攻击钓鱼邮件攻击这种问题时我们希望能够通过数据分析和挖掘的方式来追踪到对手的行为特征。基于类似的use case场景我们需要先理解各种安全数据的攻防模型以及数据类型。对此我们把类型设定在Windows主机并以Windows感染的邮件钓鱼场景为例说说威胁建模方法如下所示：\n\n理解网络威胁情报(Cyber Threat Intelligence)和威胁建模方法(Threat modeling security)的基础知识。\n在威胁情报体系中我们为了数据之间能够共享.在基于HTTPS的协议中定义了一种通用的共享格式叫TAXII。如下所示\nTAXII 专门用于支持以 STIX 为代表的 CTI (Cyber Threat Intelligence)信息交换机制，在数据分析领域甚至是威胁情报领域我们能通过统一的STIX数据格式，将怀疑、妥协和归因的所有方面通过对象和描述性关系清楚地表示。STIX 信息在2.1版本中定义了18个STIX域对象(SDO)如下所示：\nSTIX信息可以为分析师直观地表示钻石模型中所对应的信息。当我们在完成大数据安全分析平台数据分类分级治理阶段的时候就可以将STIX信息存储在数据仓库中供分析师使用。\n另外一个需要说明的方面是针对威胁情报中的钻石模型我们同样需要有所认识。由于攻击者的攻击是阶段性的所以CTI网络威胁情报将其以钻石模型来对应STIX的数据层级并以Json格式进行展示如图所示：\n从而构成了威胁情报数据共享映射关系金字塔\n2、如何理解威胁框架和威胁建模如上所述我们需要理解的第二个是Att&amp;ck攻击模型框架这个框架位于钻石模型的TTPs金字塔顶层在这里详细描述了攻击者的攻击手段和攻击阶段以及对应的唯一标识ID我们能够通过对攻击阶段的建模来进行相应安全设备攻击事件的相关映射如下所示：我们需要创建一个图层来进行威胁建模\n添加安全日志备注字段名称对其字段内容(value)进行攻击图层关系映射\n当攻击者进行钓鱼攻击时第一个所发生的事情应该是信息收集或者邮件钓鱼这里我们起一个本地的威胁建模环境并选择其攻击阶段的子攻击类型模拟TTp的对手行为\n\n\n如上所述我们可以通过一些标有ID编号的行为模拟攻击者采用的技术并给它们标注颜色，另外一个就是我们也可以通过ID区查询相关的技术手段和所关联到的APT组织\n\n\n最后在通过打分。对比攻击方法来寻找其行为相似性并和团队完成所有的分析行为报告\n作者大家好，我是伏念。\n一位大数据安全分析平台研发工程师和一位安全数据分析专家同时也是一位威胁建模专家。\n今天我们通过常见的攻防场景来围绕数据分析理解如何为企业设计威胁模型。\n为准备自研大数据安全分析平台的公司提供一些专业性上的帮助。\n\n","slug":"blog/attandck","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"大数据安全","author_index":"安全书"},{"id":"32b9ddc7db8ff85b8d7bba8c3123eba0","title":"白帽子讲Web安全","content":"购买链接： 点击购买\n作者： 吴翰清内容简介：在互联网时代，数据安全与个人隐私受到了前所未有的挑战，各种新奇的攻击技术层出不穷。如何才能更好地保护我们的数据？《白帽子讲Web安全》将带你走进web安全的世界，让你了解Web安全的方方面面。黑客不再变得神秘，攻击技术原来我也可以会，小网站主自己也能找到正确的安全道路。大公司是怎么做安全的，为什么要选择这样的方案呢？你能在《白帽子讲Web安全》中找到答案。详细的剖析，让你不仅能“知其然”，更能“知其所以然”。 　　《白帽子讲Web安全》是根据作者吴翰清若干年实际工作中积累下来的丰富经验而写成的，在解决方案上具有极强的可操作性，深入分析了各种错误的解决方案与误区，对安全工作者有很好的参考价值。安全开发流程与运营的介绍，对同行业的工作具有指导意义。\n推荐理由：本书对Web安全各个方面都进行了较详细的分析，在掌握基本知识后阅读此书更佳。\n","slug":"blog/baimaozijianganquan","date":"2023-02-01T09:03:30.028Z","categories_index":"书籍","tags_index":"Web安全,电子工业出版社","author_index":"安全书"},{"id":"bcd4403de43b8cbd12066144ee39876d","title":"绕过CDN查找真实IP方法","content":"相信大家平时在做渗透测试时，经常会碰到部署了CDN的网站，我们有时候想要获取某站的源站ip，方法有很多，今天我给大家总结一下，赠人玫瑰，手有余香。\nCDN简介：CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。\n域名解析过程:传统访问：用户访问域名–&gt;解析IP–&gt;访问目标主机CDN模式：用户访问域名–&gt;CDN节点–&gt;真实IP–&gt;目标主机\n验证网站有无CDN方法:利用“全球Ping”快速检测目标网址是否存在CDN，如果返回域名解析对应多个 IP 地址多半是使用了 CDN,如果得到的IP归属地是某CDN服务商，或者每个地区得到的IP地址不一样则说明可能存在CDN，可用以下几个网站检测！http://ping.chinaz.comhttp://ping.aizhan.com/http://www.webkaka.com/ping.aspx\n\n方法总结：1.查询历史DNS记录：查看 IP 与 域名绑定的历史记录，可能会存在使用 CDN 前的记录，相关查询网站有：DNS查询：https://dnsdb.io/zh-cn/微步在线：https://x.threatbook.cn/在线域名信息查询：http://toolbar.netcraft.com/site_report?url=DNS、IP等查询：http://viewdns.info/CDN查询IP：https://tools.ipip.net/cdn.phpSecurityTrails平台：https://securitytrails.com/domain/www.baidu.com/history/aIP138:http://site.ip138.com\n2.利用MX记录（邮件查找）：查看由网站发送的邮件原文，寻找Received参数信息。\n3.利用网站漏洞：目标敏感文件泄露，例如：phpinfo之类的探针、GitHub信息泄露等；XSS盲打，命令执行反弹shell，SSRF等。\n4.查询子域名：毕竟 CDN 还是不便宜的，所以很多站长可能只会对主站或者流量大的子站点做了 CDN，而很多小站子站点又跟主站在同一台服务器或者同一个C段内，此时就可以通过查询子域名对应的 IP 来辅助查找网站的真实IP。IP138:http://site.ip138.com（查询地址同方法1）Google 搜索，例如：用语法”site:baidu.com -www”就能查看除www外的子域名。子域名扫描器\n5.网络空间引擎搜索：常见的有以前的钟馗之眼，shodan，fofa搜索。以fofa为例，只需输入：title:“网站的title关键字”或者body：“网站的body特征”就可以找出fofa收录的有这些关键字的ip域名，很多时候能获取网站的真实ip。钟馗之眼：https://www.zoomeye.org/Shodan：https://www.shodan.io/FOFA：https://fofa.so/\n6.利用HTTP标头：借助SecurityTrails这样的平台，任何人都可以在茫茫的大数据搜索到自己的目标，甚至可以通过比较HTTP标头来查找到原始服务器。特别是当用户拥有一个非常特别的服务器名称与软件名称时，攻击者找到你就变得更容易。如果要搜索的数据相当多，如上所述，攻击者可以在Censys上组合搜索参数。假设你正在与1500个Web服务器共享你的服务器HTTP标头，这些服务器都发送的是相同的标头参数和值的组合。而且你还使用新的PHP框架发送唯一的HTTP标头（例如：X-Generated-Via：XYZ框架），目前约有400名网站管理员使用了该框架。而最终由三个服务器组成的交集，只需手动操作就可以找到了IP，整个过程只需要几秒钟。例如，Censys上用于匹配服务器标头的搜索参数是80.http.get.headers.server :，查找由CloudFlare提供服务的网站的参数如下：\n180.http.get.headers.server:cloudflare\n\nhttps://censys.io/ipv4\n7.利用SSL证书：(1).我们可以利用空间引擎进行 SSL 证书探测，搜索语句：\n1443.https.tls.certificate.parsed.extensions.subject_alt_name.dns_names:www.baidu.com\n\nhttps://censys.io/ipv4\n(2).还有一种方式，就是搜集 SSL 证书 Hash，然后遍历 ip 去查询证书 hash，如果匹配到相同的，证明这个 ip 就是那个 域名同根证书的服务器真实 ip。简单来说，就是遍历 0.0.0.0/0:443，通过 ip 连接 https 时，会显示证书。当然，也可以用 censys 等引擎，baidu.com证书的搜索查询参数为：parsed.names:baidu.com 只显示有效证书的查询参数为:tags.raw:trusted 攻击者可以在Censys上实现多个参数的组合，这可以通过使用简单的布尔逻辑来完成。组合后的搜索参数为：\n1parsed.names: baidu.com and tags.raw: trusted\n\nCensys将向你显示符合上述搜索条件的所有标准证书，以上这些证书是在扫描中找到的。\n要逐个查看这些搜索结果，攻击者可以通过单击右侧的“Explore”，打开包含多个工具的下拉菜单。What’s using this certificate? &gt; IPv4 Hosts此时，攻击者将看到一个使用特定证书的IPv4主机列表，而真实原始 IP就藏在其中。\n你可以通过导航到端口443上的IP来验证，看它是否重定向到xyz123boot.com？或它是否直接在IP上显示网站？隐藏服务具有SSL证书，要查找它使用的IPv4主机，只需将”SHA1 fingerprint”（签名证书的sha1值）粘贴到Censys IPv4主机搜索中，即可找到证书，使用此方法可以轻松找到配置错误的Web服务器。\n8.用网站返回内容：如果原始服务器IP也返回了网站的内容，那么可以在网上搜索大量的相关数据。浏览网站源代码，寻找独特的代码片段。在JavaScript中使用具有访问或标识符参数的第三方服务（例如Google Analytics，reCAPTCHA）是攻击者经常使用的方法。或者说用title，毕竟竟每个网站的title基本上都是独一无二的。以下是从HackTheBox网站获取的Google Analytics跟踪代码示例：ga（’create’，’UA-93577176-1’，’auto’）;可以使用80.http.get.body：参数通过body/source过滤Censys数据，不幸的是，正常的搜索字段有局限性，但你可以在Censys请求研究访问权限，该权限允许你通过Google BigQuery进行更强大的查询。Shodan是一种类似于Censys的服务，也提供了http.html搜索参数。搜索示例：https://www.shodan.io/search?query=http.html%3AUA-32023260-1\n9.Nslookup查询：查询域名的NS记录、MX记录、TXT记录等很有可能指向的是真实ip或同C段服务器。\n10.全网扫描（不推荐）:需要找 baidu.com网站的真实 IP，我们首先从 apnic 获取 IP 段，然后使用 Zmap 的 banner-grab 扫描出来 80 端口开放的主机进行 banner 抓取，最后在 http-req 中的 Host 写baidu.com。\n11.F5 LTM解码法:当服务器使用F5 LTM做负载均衡时，通过对set-cookie关键字的解码真实ip也可被获取，例如：Set-Cookie: BIGipServerpool_8.29_8030=487098378.24095.0000，先把第一小节的十进制数即487098378取出来，然后将其转为十六进制数1d08880a，接着从后至前，以此取四位数出来，也就是0a.88.08.1d，最后依次把他们转为十进制数10.136.8.29，也就是最后的真实ip。12.其他：使用ddos消耗完CDN账号流量使其回源；等；\n希望本文能对你有所帮助，谢谢。\n不要等夕阳西下时才对自己说，想当初、如果、要是，之类的话！不为别人，只为做一个连自己都羡慕的人。\n本文转载自天乐博客：http://blog.tianles.com/96.html\n","slug":"blog/cdn-ip","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"安全技术","author_index":"安全书"},{"id":"3141f157b979681af7ded27775c68b78","title":"Clickhouse的Docker版本查询","content":"Clickhouse的Docker版本查询。\n123select service, count(service) as cnt from x_main_all where date &gt; &#x27;2021-01-01&#x27;  and date &lt;&#x27;2022-01-27&#x27;    group by service  order by cnt desc limit 1000;select product, count(product) as cnt from x_main_all where date &gt; &#x27;2021-01-01&#x27;  and date &lt;&#x27;2022-01-27&#x27;    group by product  order by cnt desc limit 1000;docker run -it --rm yandex/clickhouse-client -h xxx.cn --port 9000 -m -u username --password passwd -d usern\n\n\n\n","slug":"blog/clickhouse","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"ClickHouse","author_index":"安全书"},{"id":"cb9d1e5e022c207d55ccf114e6e4aa69","title":"一种小语言Edgelang","content":"找回了当时测试时用OpenResty Edgelang的代码。\n1234567891011121314151617uri contains &quot;SQL&quot;=&gt;\tset-upstream(&#x27;HoneyPot_1&#x27;);\t\treq-header(&quot;Content-Type&quot;) contains &quot;multipart/form-data&quot;,\treq-header(&quot;Content-Type&quot;) !contains rx&#123;^multipart/form-data[\\s\\S]+&#125; =&gt;\twaf-mark-evil(message: &quot;CVE-2017-5638 Struts&quot;, level: &quot;super&quot;),\tset-upstream(&#x27;HoneyPot_2&#x27;);uri(&quot;/shop&quot;), client-province(&#x27;Guangdong&#x27;),\tua-is-mobile() =&gt;\tlimit-req-rate(key: client-addr, target-rate: 5 [r/s], reject-rate: 10 [r/s]), limit-resp-data-rate(441 [mB/s]);uri(&quot;/shop&quot;), client-country(&quot;US&quot;) =&gt;\tlimit-req-rate(key: client-addr, target-rate: 5 [r/s], reject-rate: 10 [r/s]), sleep(0.5);req-header(“Content-Type”) contains “multipart/form-data”,req-header(“Content-Type”) !contains rx&#123;^multipart/form-data[\\s\\S]+&#125; =&gt;\twaf-mark-evil(message: &quot;CVE-XXX-XXX &quot;, level: &quot;super&quot;),\n\n","slug":"blog/edgelang","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"OpenResty","author_index":"安全书"},{"id":"70e08f36c56f78f54175b098fc27d77a","title":"ElasticSearch最大返回结果量大小设置","content":"123curl -H &quot;Content-Type: application/json&quot; -XPUT &#x27;http://192.168.0.5:9205/_all/_settings?preserve_existing=true&#x27;  -d &#x27;&#123;  &quot;index.max_result_window&quot; : &quot;100000&quot;&#125;&#x27;\n","slug":"blog/elasticsearch","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"ElasticSearch","author_index":"安全书"},{"id":"87b14f55648ecfc38c289ee95a9a3dbf","title":"SSH解决The authenticity of host xxx can't be established.","content":"通道机突然出现了链接不上的情况，最后就直接在SSH的IP约束检查去掉。\n修改配置文件1vim /etc/ssh/ssh_config\n\n\n添加不检查主机的约束的选项12StrictHostKeyChecking noUserKnownHostsFile /dev/null\n\n","slug":"blog/jumperserver","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"运维记录","author_index":"安全书"},{"id":"286f44c415f4bbbe2e2949b688d0fc20","title":"iptables限制IP访问","content":"设定主机可访问的端口。\n123456iptables -I INPUT -s 192.168.0.5 -p tcp --dport 80 -j ACCEPTiptables -D INPUT -s 192.168.0.5 -p tcp --dport 80 -j ACCEPTiptables -I INPUT -s 192.168.0.5 -p tcp --dport 27017 -j ACCEPTiptables -I INPUT -s 192.168.0.5 -p tcp --dport 27017 -j ACCEPTiptables -I INPUT -s 127.0.0.1 -p tcp --dport 27017 -j ACCEPTiptables -I INPUT -s 192.168.0.5 -p tcp --dport 27017 -j ACCEPT\n","slug":"blog/iptables","date":"2023-02-01T09:03:30.028Z","categories_index":"文章","tags_index":"iptables,linux","author_index":"安全书"},{"id":"809b84876322fff2ab4810eef75c2b8c","title":"《墨守之道》Web服务架构设计与实践|计算机网络安全技术","content":"购买链接： 点击购买\n编辑推荐\n\n1. 独特视角解析网络攻防之道本书借鉴了墨家思想，从多个方面解读Web安全的攻防原理，不仅涉及Web服务与安全的基础理论，也讲解了很多时下热门的安全技术，例如复载均衡、WAF、日志审计、蜜罐等。\n2. 实用案例探秘企业级安全之道本书案例丰富，适合读者边学边进行实践参考，能够为安全领域的研发人员、运维人员、高校师生、培训机构提供更全面的技术指导和学习素材。\n3. 原理解析深入浅出，经典案例有源码配套本书由资深的安全从业者和高校老师编写，融合了产业界和学界对网络信息安全的深度思考和实践，书中的典型案例还有配套的源码文件提供，方便读者使用。 \n内容简介\n\n近年来，信息技术的广泛应用极大地促进了社会进步，也方便了人们的工作和生活，随之而来的网络安全问题日益突显。如何构建安全可靠的网络环境，如何与时俱进地把新技术纳入网络安全防护的实践当中，成为网络安全工作者的重要课题。 本书聚焦于 Web 服务常用的安全技术，以案例形式展示 Web 服务所面临的威胁，并给出了丰富多样的解决方案。本书由浅入深地介绍了 Web 安全的相关主题，包括 Web 应用程序基础理论、Web服务器与负载均衡、HTTPS和CDN的安全问题、Web服务的安全因素、如何保护Web服务、WAF原理与实践、Web日志审计、蜜罐技术、大数据时代的Web安全、网络安全解决方案等内容。 本书适合网络安全领域的研发人员、运维人员、高校师生、培训机构等群体阅读参考。\n作者简介\n\n\n盛洋，新浪网高级安全与开发工程师，长期从事企业信息系统开发与嵌入式系统开发。在进入互联网信息安全领域之后，他将企业级信息安全工程方法与对嵌入式系统高性能的要求融入互联网安全信息系统的开发实践中，深度参与了互联网企业云服务防护实践和安全信息系统的构建。他还是《安全客》季刊的作者，FreeBuf安全智库指导专家顾问及“年度作者”。他也是一名活跃的技术博主，运营公众号“糖果的实验室”。 \n李华峰，信息安全顾问和自由撰稿人，FreeBuf安全智库指导专家顾问，多年来一直从事网络安全渗透测试方面的研究工作，在网络安全部署、网络攻击与防御以及社会工程学等方面有十分丰富的教学和实践经验。他还是一位高产的技术作者，已出版多本原创著作和译著，为学界和业界的网络安全教学和实践提供了助力。他经常通过公众号“邪灵工作室”给大家分享图书相关的资料和实用的技术指南\n","slug":"blog/mozidao","date":"2022-01-12T18:00:36.000Z","categories_index":"书籍","tags_index":"Web安全,人民邮电出版社,安全图书","author_index":"盛洋"}]