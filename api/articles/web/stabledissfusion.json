{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"web/stabledissfusion","date":"2023-02-16T07:45:35.482Z","updated":"2023-02-28T09:46:52.582Z","comments":true,"path":"api/articles/web/stabledissfusion.json","keywords":null,"cover":[],"content":"<h1 id=\"在搭载-M1-及-M2-芯片-MacBook-设备上玩-Stable-Diffusion-模型\"><a href=\"#在搭载-M1-及-M2-芯片-MacBook-设备上玩-Stable-Diffusion-模型\" class=\"headerlink\" title=\"在搭载 M1 及 M2 芯片 MacBook 设备上玩 Stable Diffusion 模型\"></a>在搭载 M1 及 M2 芯片 MacBook 设备上玩 Stable Diffusion 模型</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><h2 id=\"Excerpt\"><a href=\"#Excerpt\" class=\"headerlink\" title=\"Excerpt\"></a>Excerpt</h2></blockquote>\n<blockquote>\n<p>本篇文章，我们聊了如何使用搭载了 Apple Silicon 芯片（M1 和 M2 CPU）的 MacBook 设备上运行 Stable Diffusion 模型。 </p></blockquote>\n<p>写在前面 </p>\n<p>在上一篇文章《使用 Docker 来快速上手中文 Stable Diffusion 模型：太乙》中，我们聊过…</p>\n<hr>\n<p>本篇文章，我们聊了如何使用搭载了 Apple Silicon 芯片（M1 和 M2 CPU）的 MacBook 设备上运行 Stable Diffusion 模型。</p>\n<h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><p>在上一篇文章《使用 Docker 来快速上手中文 Stable Diffusion 模型：太乙》中，我们聊过了如何使用配备了“传统的 Nvidia 显卡”的设备（云服务器）来运行 Stable Dif fusion 模型。在之前的文章中我提到过，接下来将聊聊如何使用 CPU 来运行 “SD 模型应用”。</p>\n<p>本篇文章，我们就先从 Apple Silicon 这类 ARM 芯片开始（M1 / M1 Pro / M1 Max / M1 Ultra / M2），用 CPU 来运行 Stable Diffusion 。十一月末，为 Apple Core ML Tools 开源项目贡献代码的主要工程师之一，正式发布了一个新的开源项目：apple/ml-stable-diffusion。</p>\n<p>下面我们就来聊聊这个项目该如何简单、快速的上手。</p>\n<h3 id=\"支持运行的设备\"><a href=\"#支持运行的设备\" class=\"headerlink\" title=\"支持运行的设备\"></a>支持运行的设备</h3><p>本文中，我的实验环境是 Apple M2 CPU 的 MacBook Pro，机器内存容量为 16GB。同样还能够运行本文的设备包含：</p>\n<ul>\n<li><p>  2022 年生产的MacBook Air (M2)、13寸的 MacBook Pro (M2)、Mac Studio (2022)</p>\n</li>\n<li><p>  2021 年生产的 14寸和16寸的 MacBook Pro、24寸的 iMac (M1)</p>\n</li>\n<li><p>  2020 年生产的 Mac mini (M1)、MacBook Air (M1)、13寸的 MacBook Pro (M1)</p>\n</li>\n<li><p>  当然，还有搭载了 M1 芯片的第五代 iPad Pro</p>\n</li>\n</ul>\n<h2 id=\"基础环境准备\"><a href=\"#基础环境准备\" class=\"headerlink\" title=\"基础环境准备\"></a>基础环境准备</h2><p>想要在 ARM 芯片的 Mac 设备上运行这个模型应用，我们需要做几件事：</p>\n<ul>\n<li><p>  准备 Python 基础运行环境</p>\n</li>\n<li><p>  准备软件运行所需要的软件包</p>\n</li>\n</ul>\n<h3 id=\"为-MacOS-设备安装-Python-环境管理工具\"><a href=\"#为-MacOS-设备安装-Python-环境管理工具\" class=\"headerlink\" title=\"为 MacOS 设备安装 Python 环境管理工具\"></a>为 MacOS 设备安装 Python 环境管理工具</h3><p>在《用让新海诚本人惊讶的 AI 模型制作属于你的动漫视频》这篇文章中，我分享过关于“使用 Conda 简化 Python 程序环境准备工作”，正巧年底 Conda 版本更新，这里就顺带也更新一个版本的安装和使用方式。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/img_convert/f89a21c098f5d719d82ebeeaf90e5e28.jpeg\" alt=\"CONDA 开源项目\"></p>\n<p>虽然我们可以从 Conda 官方网站的下载页面得到合适的安装程序。不过，我一般从 Conda 官方的 “Archive” 页面进行下载，因为能够更加直观的看到，我们想要下载的目标文件的各种信息，比如：名称、版本、尺寸、更新时间、文件指纹。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">Filename                          Size   Last Modified       SHA256</span><br><span class=\"line\"></span><br><span class=\"line\">Anaconda3-2022.10-MacOSX-arm64.sh 472.5M 2022-10-17 16:15:38 200700077db8eed762fbc996b830c3f8cc5a2bb7d6b20bb367147eb35f2dcc72</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这里为了更快的得到下载文件，可以通过“清华源”中的 Conda 镜像来加速下载过程。比如，官方的原始下载地址 <code>https://repo.anaconda.com/archive/Anaconda3-2022.10-MacOSX-arm64.sh</code> ，那么加速下载的地址就是：<code>https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2022.10-MacOSX-arm64.sh</code>，完成 Conda 安装文件下载之后，我们可以执行 <code>shasum -a 256</code> 来验证下载文件的完整性：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">shasum -a 256 ~/Downloads/Anaconda3-2022.10-MacOSX-arm64.sh </span><br><span class=\"line\"></span><br><span class=\"line\">200700077db8eed762fbc996b830c3f8cc5a2bb7d6b20bb367147eb35f2dcc72  /Users/soulteary/Downloads/Anaconda3-2022.10-MacOSX-arm64.sh</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>接着，执行 <code>bash Anaconda3-2022.10-MacOSX-arm64.sh</code> 进行安装，“一路 Next”，完成程序的安装即可。</p>\n<p>和之前的文章里的观点相同，国内用户推荐在使用 Conda 时，先进行软件源配置操作。这样可以减少在下载软件包过程中造成的不必要时间浪费。使用 <code>vi ~/.condarc</code> 编辑 Conda 配置文件，在其中加入下面的内容（以“清华源”为例）：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">channels:- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/- https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/- https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/- defaults</span><br><span class=\"line\"></span><br><span class=\"line\">show_channel_urls: <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在完成了 <code>~/.condarc</code> 的内容修改后，重启 Shell。然后，使用 <code>conda info</code> 查看配置是否生效：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">conda infoactive environment : baseactive env location : /Users/soulteary/anaconda3shell level : 1user config file : /Users/soulteary/.condarcpopulated config files : /Users/soulteary/.condarcconda version : 22.9.0conda-build version : 3.22.0python version : 3.9.13.final.0virtual packages : __osx=13.0.1=0__unix=0=0__archspec=1=arm64base environment : /Users/soulteary/anaconda3  (writable)conda av data dir : /Users/soulteary/anaconda3/etc/condaconda av metadata url : Nonechannel URLs : https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/osx-arm64https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/noarchhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/osx-arm64https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/noarchhttps://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/osx-arm64https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/noarchhttps://repo.anaconda.com/pkgs/main/osx-arm64https://repo.anaconda.com/pkgs/main/noarchhttps://repo.anaconda.com/pkgs/r/osx-arm64https://repo.anaconda.com/pkgs/r/noarchpackage cache : /Users/soulteary/anaconda3/pkgs/Users/soulteary/.conda/pkgsenvs directories : /Users/soulteary/anaconda3/envs/Users/soulteary/.conda/envsplatform : osx-arm64user-agent : conda/22.9.0 requests/2.28.1 CPython/3.9.13 Darwin/22.1.0 OSX/13.0.1UID:GID : 502:20netrc file : Noneoffline mode : False</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>如果输出的内容中包含我们刚刚设置的“清华源”，就说明我们的配置生效了。</p>\n<h3 id=\"快速准备-MacOS-上的-Python-运行环境\"><a href=\"#快速准备-MacOS-上的-Python-运行环境\" class=\"headerlink\" title=\"快速准备 MacOS 上的 Python 运行环境\"></a>快速准备 MacOS 上的 Python 运行环境</h3><p>在完成 Conda 的安装之后，我们就可以用它来快速的创建不影响本地机器环境（MacOS），只和项目关联的干净的 Python 运行环境了。</p>\n<p>检查 apple/ml-stable-diffusion/setup.py 文件，我们可以看到，项目支持运行的环境有 Python 3.7 ～ Python 3.9，那我们随便取个中间数 3.8 吧：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">conda create -n coreml_stable_diffusion python=3.8 -y</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>等待上面的命令执行完毕，我们指定的名为 <code>coreml_stable_diffusion</code> 的环境就初始化好啦，环境使用的具体 Python 版本为 3.8 （虚拟环境的版本可以和系统不一样）。</p>\n<p>当然，默认创建好之后，并不会直接切换到创建好的新环境，我们还需要使用命令，来完成环境的切换。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">conda activate coreml_stable_diffusion</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>当命令执行完毕之后，我们会看到终端前的展示字符串会出现变化，展示我们当前正所处于的虚拟环境：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">(base) <span class=\"comment\"># conda activate coreml_stable_diffusion</span></span><br><span class=\"line\"></span><br><span class=\"line\">(coreml_stable_diffusion) <span class=\"comment\">#</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>因为，我们后续需要使用 <code>pip</code> 命令来安装程序依赖的软件包，为了减少时间的浪费，这里我们同样可以使用命令，来调整软件下载源为“清华源”：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">pip config <span class=\"built_in\">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>如果我们关闭了终端，你会发现环境“失效了”，这时还是可以用和上文中提到的相同的命令 <code>conda activate</code>，来激活（切换）回我们之前配置好的环境。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">conda activate coreml_stable_diffusion</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"避免-MacOS-上-Tokenizers-软件包安装出错\"><a href=\"#避免-MacOS-上-Tokenizers-软件包安装出错\" class=\"headerlink\" title=\"避免 MacOS 上 Tokenizers 软件包安装出错\"></a>避免 MacOS 上 Tokenizers 软件包安装出错</h3><p>如果你经常在 MacOS 上折腾 “Huggingface” 等项目，尤其是运行相对新一些的模型项目，大概率会遇到 “Failed building wheel for tokenizers”这个问题。</p>\n<p>解决问题的方法很简单，只需要在 MacOS 上完成 Rust 的安装即可：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">curl https://sh.rustup.rs -sSf | sh</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>完成安装之后，可以使用 <code>rustc --version</code> 来做一个简单的命令“可执行”的验证：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># rustc --version</span></span><br><span class=\"line\"></span><br><span class=\"line\">rustc 1.65.0 (897e37553 2022-11-02)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>当然，为了加速 rust 软件包的下载，同样建议在 Rust 的配置文件（<code>~/.cargo/config</code>）中，完成“清华源”的配置：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># vi ~/.cargo/config</span></span><br><span class=\"line\"></span><br><span class=\"line\">[source.crates-io]</span><br><span class=\"line\"></span><br><span class=\"line\">registry = <span class=\"string\">&quot;https://github.com/rust-lang/crates.io-index&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">replace-with = <span class=\"string\">&#x27;tuna&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">[source.tuna]</span><br><span class=\"line\"></span><br><span class=\"line\">registry = <span class=\"string\">&quot;https://mirrors.tuna.tsinghua.edu.cn/git/crates.io-index.git&quot;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>完成配置文件的保存，接下来在遇到需要 Rust 编译，或下载依赖包的时候，速度也会变的飞快。</p>\n<p>如果你没有补全 <code>rustc</code> 的依赖，那么大概率会遇到类似下面的报错：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">Building wheels <span class=\"keyword\">for</span> collected packages: pyyaml, tokenizersBuilding wheel <span class=\"keyword\">for</span> pyyaml (pyproject.toml) ... doneCreated wheel <span class=\"keyword\">for</span> pyyaml: filename=PyYAML-6.0-cp38-cp38-macosx_11_0_arm64.whl size=45335 sha256=e27236fa2771f8d6ffbba947c48931a8fcf95ad33d77b91d4c693d04d5344710Stored <span class=\"keyword\">in</span> directory: /Users/soulteary/Library/Caches/pip/wheels/fe/be/21/a238a4532fd03d32998d6a07c6b4f572ea8cb4eaa89ddc2a41Building wheel <span class=\"keyword\">for</span> tokenizers (pyproject.toml) ... errorerror: subprocess-exited-with-error× Building wheel <span class=\"keyword\">for</span> tokenizers (pyproject.toml) did not run successfully.│ <span class=\"built_in\">exit</span> code: 1╰─&gt; [51 lines of output]running bdist_wheelrunning buildrunning build_pycreating buildcreating build/lib.macosx-11.1-arm64-cpython-38creating build/lib.macosx-11.1-arm64-cpython-38/tokenizerscopying py_src/tokenizers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/modelscopying py_src/tokenizers/models/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/modelscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/decoderscopying py_src/tokenizers/decoders/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/decoderscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/normalizerscopying py_src/tokenizers/normalizers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/normalizerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/pre_tokenizerscopying py_src/tokenizers/pre_tokenizers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/pre_tokenizerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/processorscopying py_src/tokenizers/processors/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/processorscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/trainerscopying py_src/tokenizers/trainers/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/trainerscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/byte_level_bpe.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/sentencepiece_unigram.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/sentencepiece_bpe.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/base_tokenizer.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/char_level_bpe.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscopying py_src/tokenizers/implementations/bert_wordpiece.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/implementationscreating build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolscopying py_src/tokenizers/tools/__init__.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolscopying py_src/tokenizers/tools/visualizer.py -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolscopying py_src/tokenizers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizerscopying py_src/tokenizers/models/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/modelscopying py_src/tokenizers/decoders/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/decoderscopying py_src/tokenizers/normalizers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/normalizerscopying py_src/tokenizers/pre_tokenizers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/pre_tokenizerscopying py_src/tokenizers/processors/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/processorscopying py_src/tokenizers/trainers/__init__.pyi -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/trainerscopying py_src/tokenizers/tools/visualizer-styles.css -&gt; build/lib.macosx-11.1-arm64-cpython-38/tokenizers/toolsrunning build_extrunning build_rusterror: can<span class=\"string\">&#x27;t find Rust compilerIf you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.To update pip, run:pip install --upgrade pipand then retry package installation.If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.[end of output]note: This error originates from a subprocess, and is likely not a problem with pip.ERROR: Failed building wheel for tokenizers</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Successfully built pyyaml</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">Failed to build tokenizers</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"完成-Stable-Diffusion-项目的初始化\"><a href=\"#完成-Stable-Diffusion-项目的初始化\" class=\"headerlink\" title=\"完成 Stable Diffusion 项目的初始化\"></a>完成 Stable Diffusion 项目的初始化</h3><p>我们可以通过 <code>git clone</code> 命令，或者直接下载包含代码的压缩包，来获得项目的代码：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">git <span class=\"built_in\">clone</span> https://github.com/apple/ml-stable-diffusion.git</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>项目比较小，所以下载速度还是蛮快的：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># git clone https://github.com/apple/ml-stable-diffusion.gitCloning into &#x27;ml-stable-diffusion&#x27;...</span></span><br><span class=\"line\"></span><br><span class=\"line\">remote: Enumerating objects: 65, <span class=\"keyword\">done</span>.</span><br><span class=\"line\"></span><br><span class=\"line\">remote: Counting objects: 100% (14/14), <span class=\"keyword\">done</span>.</span><br><span class=\"line\"></span><br><span class=\"line\">remote: Compressing objects: 100% (13/13), <span class=\"keyword\">done</span>.</span><br><span class=\"line\"></span><br><span class=\"line\">remote: Total 65 (delta 0), reused 14 (delta 0), pack-reused 51</span><br><span class=\"line\"></span><br><span class=\"line\">Receiving objects: 100% (65/65), 9.05 MiB | 406.00 KiB/s, <span class=\"keyword\">done</span>.</span><br><span class=\"line\"></span><br><span class=\"line\">Resolving deltas: 100% (1/1), <span class=\"keyword\">done</span>.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>将工作目录切换到项目目录中，然后使用 <code>pip install</code> 完成项目依赖的安装：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">cd</span> ml-stable-diffusion</span><br><span class=\"line\"></span><br><span class=\"line\">pip install -r requirements.txt</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>至此，基础环境准备工作就都就绪了。</p>\n<h2 id=\"转换和运行模型应用\"><a href=\"#转换和运行模型应用\" class=\"headerlink\" title=\"转换和运行模型应用\"></a>转换和运行模型应用</h2><p>基础环境就绪之后，我们需要转换 Huggingface 上的 PyTorch / TF 开放模型到 Apple Core ML 模型格式。</p>\n<h3 id=\"转换-PyTorch-模型为-Apple-Core-ML-模型\"><a href=\"#转换-PyTorch-模型为-Apple-Core-ML-模型\" class=\"headerlink\" title=\"转换 PyTorch 模型为 Apple Core ML 模型\"></a>转换 PyTorch 模型为 Apple Core ML 模型</h3><p>项目仓库中 <code>python_coreml_stable_diffusion/torch2coreml.py</code> 文件中，封装了调用 <code>coremltools.models.MLModel</code> 工具方法来转换其他格式模型到 Core ML 模型的逻辑：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">coreml_model = coremltools.models.MLModel(...)</span><br><span class=\"line\"></span><br><span class=\"line\">coreml_model.convert(...)</span><br><span class=\"line\"></span><br><span class=\"line\">coreml_model.save(...)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>所以，作为用户我们的使用就比较简单了，只需要执行下面的命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.torch2coreml --convert-unet --convert-text-encoder --convert-vae-decoder --convert-safety-checker -o ./models</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>命令执行会比较久，十来分钟左右，包含从 Huggingface 下载模型，加载并转换模型格式。默认情况下，模型使用的是 <code>CompVis/stable-diffusion-v1-4</code>，如果你希望使用其他的模型，可以通过添加 <code>--model-version</code> 参数，支持的模型版本除了默认的 “v1.4” 之外，还有： <code>runwayml/stable-diffusion-v1-5</code> 和 <code>stabilityai/stable-diffusion-2-base</code>。</p>\n<p>如果你使用的 Mac 设备是 8GB 版本，在执行过程中，会得到内存不足之类的提示，可以用下面的命令进行替换：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.torch2coreml --convert-vae-decoder -o ./models &amp;&amp; \\</span><br><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.torch2coreml --convert-unet -o ./models &amp;&amp; \\</span><br><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.torch2coreml --convert-text-encoder -o ./models &amp;&amp; \\</span><br><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.torch2coreml --convert-safety-checker -o ./models &amp;&amp;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>命令执行完毕，我们将在 <code>./models</code> 目录，得到必须的四个模型，尺寸都不算小：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># du -hs ./models/*</span></span><br><span class=\"line\"></span><br><span class=\"line\">580M./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">235M./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">1.6G./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage95M./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>当然，相比 HuggingFace 的原始模型来说，还是小了一些的：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">du -hs ~/.cache/huggingface/diffusers/models--CompVis--stable-diffusion-v1-4/ </span><br><span class=\"line\"></span><br><span class=\"line\">5.1G/Users/soulteary/.cache/huggingface/diffusers/models--CompVis--stable-diffusion-v1-4/</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"运行转换后的模型进行验证\"><a href=\"#运行转换后的模型进行验证\" class=\"headerlink\" title=\"运行转换后的模型进行验证\"></a>运行转换后的模型进行验证</h3><p>完成模型构建之后，我们可以运行模型，来验证模型转换是否成功：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.pipeline --prompt <span class=\"string\">&quot;magic book on the table&quot;</span> -i ./models -o ./output --compute-unit ALL --seed 93</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在上面的命令中，我们做了几件事，告诉程序使用 <code>./models</code> 目录中的模型进行计算，将生成的图谱保存在 <code>./output</code> 目录中，允许使用所有类型的运算单元（<code>CPU/GPU</code>），使用一个固定的随机数种子，确保每次生成的结果都是一样的，方便我们进行测试复现。当然，最重要的是，我们将要生成图片的文本描述写在 <code>--prompt</code> 参数中，告诉模型应用要生成“一本放在桌子上的魔法书”。如果你的设备只有 8GB 的内存，这里需要调整下 <code>--compute-unit</code> 参数，指定参数值为 <code>CPU_AND_NE</code>。</p>\n<p>程序运行之后，需要等几分钟：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">WARNING:coremltools:Torch version 1.13.0 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Setting random seed to 93</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Initializing PyTorch pipe <span class=\"keyword\">for</span> reference configuration</span><br><span class=\"line\"></span><br><span class=\"line\">Fetching 16 files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00&lt;00:00, 9876.21it/s]</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Removed PyTorch pipe to reduce peak memory consumption</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Loading Core ML models <span class=\"keyword\">in</span> memory from ./models</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.4 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 73.1 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 5.5 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 2.2 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Done.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Initializing Core ML pipe <span class=\"keyword\">for</span> image generation</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Stable Diffusion configured to generate 512x512 images</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Done.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Beginning image generation.</span><br><span class=\"line\"></span><br><span class=\"line\">100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [01:50&lt;00:00,  2.17s/it]</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:__main__:Generated image has nsfw concept=False</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>当程序运行完毕之后，我们将能够在 <code>./output</code> 目录中，找到生成的图片。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/img_convert/4646a9541f414512f9458c8d197faeeb.jpeg\" alt=\"“magic book on the table”\"></p>\n<p>但是，每次使用都要等三四分钟才能得到图片，未免太慢了。而且想生成不同的图，不论是需要调整“随机数种子”，还是要改变“描述文本”，都得在命令行中完成，遇到文本特别长的时候，非常不方便。</p>\n<p>有没有什么方法，可以让 ML Stable Diffusion 的生成图片，使用起来方便些呢？</p>\n<h2 id=\"为-ML-Stable-Diffusion-编写一个-Web-UI\"><a href=\"#为-ML-Stable-Diffusion-编写一个-Web-UI\" class=\"headerlink\" title=\"为 ML Stable Diffusion 编写一个 Web UI\"></a>为 ML Stable Diffusion 编写一个 Web UI</h2><p>在以往和 Python 相关的内容里，我提到过 <code>gradio</code> 这个有趣的工具，能够为 Python 应用，快速创建简洁美观的 Web 界面。Huggingface 中非常多的应用界面都是用它完成的。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/img_convert/1e01aee9b4d20c7941200e0025189f85.jpeg\" alt=\"Python 应用 WebUI 搭建神器：Gradio\"></p>\n<p>为了解决上面的问题，我们可以用它来创建一个 Web 界面，把 ML Stable Diffusion 的图片生成和 Web 界面“绑定”到一起。实现代码很简单，不到 100 行：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> python_coreml_stable_diffusion.pipeline <span class=\"keyword\">as</span> pipelineimport gradio <span class=\"keyword\">as</span> gr</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> diffusers <span class=\"keyword\">import</span> StableDiffusionPipelinedef init(args):pipeline.logger.info(<span class=\"string\">&quot;Initializing PyTorch pipe for reference configuration&quot;</span>)pytorch_pipe = StableDiffusionPipeline.from_pretrained(args.model_version,use_auth_token=<span class=\"literal\">True</span>)user_specified_scheduler = Noneif args.scheduler <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:user_specified_scheduler = pipeline.SCHEDULER_MAP[args.scheduler].from_config(pytorch_pipe.scheduler.config)coreml_pipe = pipeline.get_coreml_pipe(pytorch_pipe=pytorch_pipe,mlpackages_dir=args.i,model_version=args.model_version,compute_unit=args.compute_unit,scheduler_override=user_specified_scheduler)<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">infer</span>(<span class=\"params\">prompt, steps</span>):</span>pipeline.logger.info(<span class=\"string\">&quot;Beginning image generation.&quot;</span>)image = coreml_pipe(prompt=prompt,height=coreml_pipe.height,width=coreml_pipe.width,num_inference_steps=steps,)images = []images.append(image[<span class=\"string\">&quot;images&quot;</span>][<span class=\"number\">0</span>])<span class=\"keyword\">return</span> imagesdemo = gr.Blocks()<span class=\"keyword\">with</span> demo:gr.Markdown(<span class=\"string\">&quot;&lt;center&gt;&lt;h1&gt;Core ML Stable Diffusion&lt;/h1&gt;Run Stable Diffusion on Apple Silicon with Core ML&lt;/center&gt;&quot;</span>)<span class=\"keyword\">with</span> gr.Group():<span class=\"keyword\">with</span> gr.Box():<span class=\"keyword\">with</span> gr.Row():<span class=\"keyword\">with</span> gr.Column():<span class=\"keyword\">with</span> gr.Row():text = gr.Textbox(label=<span class=\"string\">&quot;Prompt&quot;</span>,lines=<span class=\"number\">11</span>,placeholder=<span class=\"string\">&quot;Enter your prompt&quot;</span>,)<span class=\"keyword\">with</span> gr.Row():btn = gr.Button(<span class=\"string\">&quot;Generate image&quot;</span>)<span class=\"keyword\">with</span> gr.Row():steps = gr.Slider(label=<span class=\"string\">&quot;Steps&quot;</span>, minimum=<span class=\"number\">1</span>,maximum=<span class=\"number\">50</span>, value=<span class=\"number\">10</span>, step=<span class=\"number\">1</span>)<span class=\"keyword\">with</span> gr.Column():gallery = gr.Gallery(label=<span class=\"string\">&quot;Generated image&quot;</span>, elem_id=<span class=\"string\">&quot;gallery&quot;</span>)text.submit(infer, inputs=[text, steps], outputs=gallery)btn.click(infer, inputs=[text, steps], outputs=gallery)demo.launch(debug=<span class=\"literal\">True</span>, server_name=<span class=\"string\">&quot;0.0.0.0&quot;</span>)<span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:parser = pipeline.argparse.ArgumentParser()parser.add_argument(<span class=\"string\">&quot;-i&quot;</span>,required=<span class=\"literal\">True</span>,<span class=\"built_in\">help</span>=(<span class=\"string\">&quot;Path to input directory with the .mlpackage files generated by &quot;</span><span class=\"string\">&quot;python_coreml_stable_diffusion.torch2coreml&quot;</span>))parser.add_argument(<span class=\"string\">&quot;--model-version&quot;</span>,default=<span class=\"string\">&quot;CompVis/stable-diffusion-v1-4&quot;</span>,<span class=\"built_in\">help</span>=(<span class=\"string\">&quot;The pre-trained model checkpoint and configuration to restore. &quot;</span><span class=\"string\">&quot;For available versions: https://huggingface.co/models?search=stable-diffusion&quot;</span>))parser.add_argument(<span class=\"string\">&quot;--compute-unit&quot;</span>,choices=pipeline.get_available_compute_units(),default=<span class=\"string\">&quot;ALL&quot;</span>,<span class=\"built_in\">help</span>=(<span class=\"string\">&quot;The compute units to be used when executing Core ML models. &quot;</span><span class=\"string\">f&quot;Options: <span class=\"subst\">&#123;pipeline.get_available_compute_units()&#125;</span>&quot;</span>))parser.add_argument(<span class=\"string\">&quot;--scheduler&quot;</span>,choices=<span class=\"built_in\">tuple</span>(pipeline.SCHEDULER_MAP.keys()),default=<span class=\"literal\">None</span>,<span class=\"built_in\">help</span>=(<span class=\"string\">&quot;The scheduler to use for running the reverse diffusion process. &quot;</span><span class=\"string\">&quot;If not specified, the default scheduler from the diffusers pipeline is utilized&quot;</span>))args = parser.parse_args()init(args)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>我们将上面的代码保存为 <code>web.py</code>，同样放在项目的 <code>python_coreml_stable_diffusion</code> 目录中。然后执行命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">python -m python_coreml_stable_diffusion.web -i ./models --compute-unit ALL</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>命令执行后，我们将得到类似下面的日志：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">WARNING:coremltools:Torch version 1.13.0 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Initializing PyTorch pipe <span class=\"keyword\">for</span> reference configuration</span><br><span class=\"line\"></span><br><span class=\"line\">Fetching 16 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00&lt;00:00, 16396.01it/s]</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Removed PyTorch pipe to reduce peak memory consumption</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Loading Core ML models <span class=\"keyword\">in</span> memory from ./models</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading text_encoder mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_text_encoder.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 4.4 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading unet mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_unet.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 73.5 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading a CoreML model through coremltools triggers compilation every time. The Swift package we provide uses precompiled Core ML models (.mlmodelc) to avoid compile-on-load.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading vae_decoder mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_vae_decoder.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 6.0 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading safety_checker mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Loading ./models/Stable_Diffusion_version_CompVis_stable-diffusion-v1-4_safety_checker.mlpackage</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.coreml_model:Done. Took 1.9 seconds.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Done.</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Initializing Core ML pipe <span class=\"keyword\">for</span> image generation</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Stable Diffusion configured to generate 512x512 images</span><br><span class=\"line\"></span><br><span class=\"line\">INFO:python_coreml_stable_diffusion.pipeline:Done.</span><br><span class=\"line\"></span><br><span class=\"line\">Running on <span class=\"built_in\">local</span> URL:  http://0.0.0.0:7860To create a public link, <span class=\"built_in\">set</span> `share=True` <span class=\"keyword\">in</span> `launch()`.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>前半段日志是不是很熟悉，和我们运行模型进行验证时，基本一致。但是在日志的结束处，我们看到程序启动了 Web 服务，并监听了 7860 端口。打开浏览器，访问这个地址，我们就能看到预期中的 Web UI 啦。完整的项目代码，可以参考 GitHub 的提交。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/img_convert/49fee032280c51ab3bba1f67e3102d67.jpeg\" alt=\"一个简洁美观的 Web UI\"></p>\n<p>都能看到界面了，不试一试是不是说不过去，我这里简单输入“colorful startrails” （绚丽星轨），然后点击 “Generate image” ，等待程序进行图片生成，图片生成完毕，将出现在右侧的 “Generated image” 图片展示框内。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/img_convert/a6b29c6692a1a231fec572d3f6c93ae7.jpeg\" alt=\"测试 “colorful startrails” 图片生成\"></p>\n<p>是不是还挺方便的，想要生成图片只需要调整文本框中的 “prompt” 文本，然后点击 “Generate image” ，等待结果展示在页面上就行了，不用去调整命令行，也不用去翻找文件夹里的图片了。并且，因为我们将程序当服务运行了起来，被模型加载只需要一次，不再需要像上文一样，每次生成图片都要先加载模型，再进行计算，能节约不少时间。</p>\n<h2 id=\"其他：一个低级-Bug\"><a href=\"#其他：一个低级-Bug\" class=\"headerlink\" title=\"其他：一个低级 Bug\"></a>其他：一个低级 Bug</h2><p>使用过其他版本的图片生成模型的同学，手里一定有“大段咒语”，当我们将超级长的咒语扔到 ML Stable Diffusion 中的时候，大概率会遇到类似下面的报错：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">Traceback (most recent call last):File <span class=\"string\">&quot;/Users/soulteary/anaconda3/envs/coreml_stable_diffusion2/lib/python3.8/runpy.py&quot;</span>, line 194, <span class=\"keyword\">in</span> _run_module_as_mainreturn _run_code(code, main_globals, None,File <span class=\"string\">&quot;/Users/soulteary/anaconda3/envs/coreml_stable_diffusion2/lib/python3.8/runpy.py&quot;</span>, line 87, <span class=\"keyword\">in</span> _run_codeexec(code, run_globals)File <span class=\"string\">&quot;/Users/soulteary/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py&quot;</span>, line 534, <span class=\"keyword\">in</span> &lt;module&gt;main(args)File <span class=\"string\">&quot;/Users/soulteary/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py&quot;</span>, line 485, <span class=\"keyword\">in</span> mainout_path = get_image_path(args)File <span class=\"string\">&quot;/Users/soulteary/ml-stable-diffusion/python_coreml_stable_diffusion/pipeline.py&quot;</span>, line 444, <span class=\"keyword\">in</span> get_image_pathos.makedirs(out_folder, exist_ok=True)File <span class=\"string\">&quot;/Users/soulteary/anaconda3/envs/coreml_stable_diffusion2/lib/python3.8/os.py&quot;</span>, line 223, <span class=\"keyword\">in</span> makedirsmkdir(name, mode)</span><br><span class=\"line\"></span><br><span class=\"line\">OSError: [Errno 63] File name too long: <span class=\"string\">&#x27;./output/.........&#x27;</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>想要避免这个问题，只有两个方法：</p>\n<p>1.  缩短你的 Prompt 文本长度</p>\n<p>2.  修改代码，避免出现超级长的文本</p>\n<p>关于如何用代码解决这个问题，我在 GitHub 的这个 PR 中有提到，感兴趣的同学可以自行“复制粘贴”，来修正这个问题。或者，等等看官方是否会合并这个请求，更新程序版本即可解决问题 😄</p>\n<h2 id=\"最后\"><a href=\"#最后\" class=\"headerlink\" title=\"最后\"></a>最后</h2><p>这篇文章就先写到这里啦。关于 Apple Mac 生态和模型的话题，其实还有不少可以聊的东西，希望后面有机会能够慢慢展开。</p>\n<p>–EOF</p>\n<hr>\n<p>我们有一个小小的折腾群，里面聚集了一些喜欢折腾的小伙伴。</p>\n<p>在不发广告的情况下，我们在里面会一起聊聊软硬件、HomeLab、编程上的一些问题，也会在群里不定期的分享一些技术沙龙的资料。</p>\n<p>喜欢折腾的小伙伴，欢迎阅读下面的内容，扫码添加好友。</p>\n<ul>\n<li><p>  关于“交友”的一些建议和看法</p>\n</li>\n<li><p>  <strong><strong>添加好友，请备注实名和公司或学校、注明来源和目的，否则不会通过审核。</strong></strong></p>\n</li>\n<li><p>  关于折腾群入群的那些事</p>\n</li>\n</ul>\n","text":"在搭载 M1 及 M2 芯片 MacBook 设备上玩 Stable Diffusion 模型 Excerpt 本篇文章，我们聊了如何使用搭载了 Apple Silicon 芯片（M1 和 M2 CPU）的 MacBook 设备上运行 Stable Diffusion 模型。 写...","link":"","photos":[],"count_time":{"symbolsCount":"24k","symbolsTime":"22 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%9C%A8%E6%90%AD%E8%BD%BD-M1-%E5%8F%8A-M2-%E8%8A%AF%E7%89%87-MacBook-%E8%AE%BE%E5%A4%87%E4%B8%8A%E7%8E%A9-Stable-Diffusion-%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">在搭载 M1 及 M2 芯片 MacBook 设备上玩 Stable Diffusion 模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Excerpt\"><span class=\"toc-text\">Excerpt</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2\"><span class=\"toc-text\">写在前面</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%94%AF%E6%8C%81%E8%BF%90%E8%A1%8C%E7%9A%84%E8%AE%BE%E5%A4%87\"><span class=\"toc-text\">支持运行的设备</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87\"><span class=\"toc-text\">基础环境准备</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B8%BA-MacOS-%E8%AE%BE%E5%A4%87%E5%AE%89%E8%A3%85-Python-%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7\"><span class=\"toc-text\">为 MacOS 设备安装 Python 环境管理工具</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%BF%AB%E9%80%9F%E5%87%86%E5%A4%87-MacOS-%E4%B8%8A%E7%9A%84-Python-%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">快速准备 MacOS 上的 Python 运行环境</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%81%BF%E5%85%8D-MacOS-%E4%B8%8A-Tokenizers-%E8%BD%AF%E4%BB%B6%E5%8C%85%E5%AE%89%E8%A3%85%E5%87%BA%E9%94%99\"><span class=\"toc-text\">避免 MacOS 上 Tokenizers 软件包安装出错</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%88%90-Stable-Diffusion-%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96\"><span class=\"toc-text\">完成 Stable Diffusion 项目的初始化</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8\"><span class=\"toc-text\">转换和运行模型应用</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BD%AC%E6%8D%A2-PyTorch-%E6%A8%A1%E5%9E%8B%E4%B8%BA-Apple-Core-ML-%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">转换 PyTorch 模型为 Apple Core ML 模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BF%90%E8%A1%8C%E8%BD%AC%E6%8D%A2%E5%90%8E%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">运行转换后的模型进行验证</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%BA-ML-Stable-Diffusion-%E7%BC%96%E5%86%99%E4%B8%80%E4%B8%AA-Web-UI\"><span class=\"toc-text\">为 ML Stable Diffusion 编写一个 Web UI</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%B6%E4%BB%96%EF%BC%9A%E4%B8%80%E4%B8%AA%E4%BD%8E%E7%BA%A7-Bug\"><span class=\"toc-text\">其他：一个低级 Bug</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%9C%80%E5%90%8E\"><span class=\"toc-text\">最后</span></a></li></ol></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"zhihu/显示器各种接口","date":"2023-02-27T05:17:52.583Z","updated":"2023-02-27T05:24:45.339Z","comments":true,"path":"api/articles/zhihu/显示器各种接口.json","keywords":null,"cover":null,"text":" HDMI HDMI（High-Definition Multimedia Interface）是一种高清多媒体接口，它是一种用于传输数字视频和音频的接口。它允许用户将他们的电视机、投影仪、DVD 播放器或其他多媒体设备连接到其他数字设备，如电脑、游戏机或者数字录音机。HDMI ...","link":"","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"other/临时问题","date":"2023-02-13T06:00:08.863Z","updated":"2023-02-13T09:17:49.312Z","comments":true,"path":"api/articles/other/临时问题.json","keywords":null,"cover":null,"text":" C语言求字符变量的后8位字符串的C语言实现。 可以使用位运算来实现： unsigned char x; unsigned char last8_str[9]; //存储最后8位字符串 for (int i = 0; i &lt; 8; i++) { last8_str[i] =...","link":"","photos":[],"count_time":{"symbolsCount":674,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}